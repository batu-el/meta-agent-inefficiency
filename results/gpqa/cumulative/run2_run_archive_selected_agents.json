[
    {
        "thought": "Let LLM first think about the principles involved in solving this task which could be helpful. By understanding the underlying principles, the model can better reason through the problem and provide a more accurate solution.",
        "name": "Step-back Abstraction",
        "code": "def forward(self, taskInfo):\n        # Instruction for understanding the principles involved in the task\n        principle_instruction = \"What are the physics, chemistry or biology principles and concepts involved in solving this task? First think step by step. Then list all involved principles and explain them.\"\n        \n        # Instruction for solving the task based on the principles\n        cot_instruction = \"Given the question and the involved principle behind the question, think step by step and then solve the task.\"\n        \n        # Instantiate LLM agents\n        principle_agent = LLMAgentBase(['thinking', 'principle'], 'Principle Agent')\n        cot_agent = LLMAgentBase(['thinking', 'answer'], 'Chain-of-Thought Agent')\n        \n        # Get the principles involved in the task\n        thinking, principle = principle_agent([taskInfo], principle_instruction)\n\n        # Use the principles to solve the task\n        thinking, answer = cot_agent([taskInfo, thinking, principle], cot_instruction)\n        return answer\n",
        "generation": "initial",
        "fitness": "95% Bootstrap Confidence Interval: (21.9%, 35.6%), Median: 28.7%",
        "acc_list": [
            0,
            0,
            0,
            0,
            0,
            1,
            0,
            0,
            0,
            1,
            0,
            0,
            0,
            1,
            0,
            0,
            1,
            0,
            1,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            1,
            0,
            0,
            0,
            0,
            1,
            1,
            0,
            0,
            0,
            1,
            1,
            1,
            0,
            1,
            0,
            1,
            1,
            1,
            0,
            0,
            1,
            0,
            1,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            1,
            0,
            0,
            0,
            0,
            0,
            0,
            1,
            1,
            1,
            0,
            0,
            0,
            1,
            0,
            1,
            1,
            0,
            1,
            0,
            1,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            1,
            0,
            0,
            0,
            0,
            1,
            1,
            0,
            0,
            0,
            1,
            1,
            0,
            0,
            0,
            1,
            1,
            1,
            1,
            0,
            0,
            1,
            0,
            1,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            1,
            0,
            1,
            1,
            0,
            0,
            0,
            1,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            1,
            1,
            0,
            1,
            0,
            1,
            0,
            0,
            1,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0
        ],
        "cost_list": [
            0.0006460000000000001,
            0.000492,
            0.0006035,
            0.0005785,
            0.001031,
            0.000731,
            0.0007385,
            0.000797,
            0.0005755000000000001,
            0.0005825,
            0.0010084999999999998,
            0.0005285,
            0.000624,
            0.0006575,
            0.0006509999999999999,
            0.0006325,
            0.0007714999999999999,
            0.000796,
            0.0009055,
            0.0006935,
            0.0007719999999999999,
            0.000657,
            0.000711,
            0.0006835,
            0.0007985000000000001,
            0.0010674999999999999,
            0.000698,
            0.0009655,
            0.0007995000000000001,
            0.0006215,
            0.0005715,
            0.0007604999999999999,
            0.0005465,
            0.0005939999999999999,
            0.0005985,
            0.0005430000000000001,
            0.0009555,
            0.0008125,
            0.000676,
            0.0008935,
            0.000661,
            0.000588,
            0.000971,
            0.0006645,
            0.0009449999999999999,
            0.0006595,
            0.0008885,
            0.000613,
            0.0007809999999999999,
            0.0005825,
            0.0011394999999999999,
            0.000827,
            0.0008424999999999999,
            0.000587,
            0.0007255,
            0.0006850000000000001,
            0.0009205,
            0.000798,
            0.0006215,
            0.0008775,
            0.0009945,
            0.0006000000000000001,
            0.0006025,
            0.0008309999999999999,
            0.0005875,
            0.0005375,
            0.0005694999999999999,
            0.000574,
            0.0009074999999999999,
            0.000837,
            0.000704,
            0.000832,
            0.000647,
            0.000565,
            0.0009215,
            0.0006325,
            0.0009699999999999999,
            0.0005145,
            0.00074,
            0.0005614999999999999,
            0.000554,
            0.0007585,
            0.000932,
            0.0007995000000000001,
            0.0008684999999999999,
            0.0006569999999999999,
            0.000791,
            0.0005565,
            0.0009170000000000001,
            0.0009735,
            0.000719,
            0.000754,
            0.0009499999999999999,
            0.0005870000000000001,
            0.0005690000000000001,
            0.000672,
            0.0006495,
            0.000671,
            0.0006915000000000001,
            0.000711,
            0.0009570000000000001,
            0.0006115,
            0.0008385,
            0.000866,
            0.000625,
            0.0006125,
            0.0007615,
            0.0006275,
            0.000823,
            0.000677,
            0.00083,
            0.000621,
            0.0005805,
            0.0008155,
            0.000938,
            0.000673,
            0.000933,
            0.00061,
            0.000801,
            0.0007650000000000001,
            0.0007794999999999999,
            0.0010535,
            0.0006915,
            0.001065,
            0.000892,
            0.000601,
            0.0005245,
            0.0006399999999999999,
            0.000688,
            0.0004955000000000001,
            0.000513,
            0.000808,
            0.0008385,
            0.000812,
            0.0007505000000000001,
            0.0008835000000000001,
            0.0005655,
            0.000571,
            0.0010165,
            0.0006475000000000001,
            0.000901,
            0.000624,
            0.000815,
            0.0006435,
            0.0005505,
            0.0007620000000000001,
            0.0009279999999999999,
            0.000735,
            0.000735,
            0.0006245000000000001,
            0.000877,
            0.000619,
            0.0009335,
            0.0010565,
            0.0006724999999999999,
            0.00103,
            0.000838,
            0.000529,
            0.000533,
            0.00074
        ]
    },
    {
        "thought": "**Insights:**\nThe 'Adaptive Iterative Refinement Agent' integrates a dynamic adjustment mechanism to iteratively refine solutions based on ongoing performance and feedback. However, the previous implementation overlaps with other iterative refinement architectures. The revised approach will focus on a more structured dynamic adjustment mechanism to ensure efficiency and effectiveness.\n\n**Overall Idea:**\nThe 'Dynamic Strategy Adjusting Agent' will dynamically adjust strategies during the iterative refinement process. This approach involves initial solution generation, dynamic evaluation and adjustment, iterative refinement based on feedback, and final synthesis.\n\n**Implementation:**\n1. **Domain Classification:** Classify the task into one of the predefined domains (Biology, Physics, Chemistry).\n2. **Initial Solution Generation:** Use domain-specific reasoning agents to generate initial solutions.\n3. **Dynamic Strategy Adjustment:** Dynamically evaluate performance and adjust strategies during refinement.\n4. **Iterative Refinement:** Refine solutions iteratively based on feedback and dynamic adjustments.\n5. **Cross-Validation:** Validate the refined solution using feedback from multiple domain experts.\n6. **Final Answer Synthesis:** Integrate all insights and generate the final answer.",
        "name": "Dynamic Strategy Adjusting Agent",
        "code": "def forward(self, taskInfo):\n    # Step 1: Domain Classification\n    domain_classification_instruction = 'Given the task, classify the domain into one of the following: Biology, Physics, Chemistry. Use detailed analysis and examples to ensure accuracy.'\n    domain_classification_agent = LLMAgentBase(['domain'], 'Domain Classification Agent')\n    domain_info = domain_classification_agent([taskInfo], domain_classification_instruction)[0]\n    domain = domain_info.content\n\n    # Handle unexpected domains\n    if domain not in ['Biology', 'Physics', 'Chemistry']:\n        domain = 'General'\n\n    # Step 2: Initial Solution Generation\n    domain_agents = {\n        'Biology': LLMAgentBase(['thinking', 'answer'], 'Biology Reasoning Agent'),\n        'Physics': LLMAgentBase(['thinking', 'answer'], 'Physics Reasoning Agent'),\n        'Chemistry': LLMAgentBase(['thinking', 'answer'], 'Chemistry Reasoning Agent')\n    }\n    initial_solution_instruction = 'Given the task, think step by step and solve the task using domain-specific knowledge.'\n    cot_agent = domain_agents.get(domain, LLMAgentBase(['thinking', 'answer'], 'General Reasoning Agent'))\n    thinking, answer = cot_agent([taskInfo], initial_solution_instruction)[0], cot_agent([taskInfo], initial_solution_instruction)[1]\n\n    # Step 3: Dynamic Strategy Adjustment\n    dynamic_adjustment_instruction = 'Based on the performance and feedback, dynamically adjust your strategy and role to improve the solution.'\n    adjustment_agent = LLMAgentBase(['new_strategy', 'adjusted_solution'], 'Adjustment Agent')\n\n    # Step 4: Iterative Refinement\n    refinement_instruction = 'Given previous feedback, refine your answer using domain-specific insights and focus on improving the solution.'\n    critic_instruction = 'Please review the answer above and provide feedback on where it might be wrong. Use domain-specific knowledge for accurate feedback. If you are absolutely sure it is correct, output True in correct.'\n    critic_agent = LLMAgentBase(['feedback', 'correct'], 'Critic Agent')\n    N_max = 5\n    i = 0\n    while i < N_max:\n        feedback, correct = critic_agent([taskInfo, thinking, answer], critic_instruction)[0], critic_agent([taskInfo, thinking, answer], critic_instruction)[1]\n        if correct.content == 'True':\n            break\n        adjustment_inputs = [taskInfo, thinking, answer, feedback]\n        new_strategy, adjusted_solution = adjustment_agent(adjustment_inputs, dynamic_adjustment_instruction)[0], adjustment_agent(adjustment_inputs, dynamic_adjustment_instruction)[1]\n        cot_inputs = [taskInfo, adjusted_solution, feedback]\n        thinking, answer = cot_agent(cot_inputs, refinement_instruction)[0], cot_agent(cot_inputs, refinement_instruction)[1]\n        i += 1\n\n    # Step 5: Cross-Validation\n    cross_validation_instruction = 'Given the refined solution, validate its accuracy and robustness using domain-specific knowledge.'\n    cross_validation_agents = {\n        'Biology': LLMAgentBase(['feedback', 'correct'], 'Biology Cross-Validator'),\n        'Physics': LLMAgentBase(['feedback', 'correct'], 'Physics Cross-Validator'),\n        'Chemistry': LLMAgentBase(['feedback', 'correct'], 'Chemistry Cross-Validator')\n    }\n    cross_validator = cross_validation_agents.get(domain, LLMAgentBase(['feedback', 'correct'], 'General Cross-Validator'))\n    cross_feedback, cross_correct = cross_validator([taskInfo, thinking, answer], cross_validation_instruction)[0], cross_validator([taskInfo, thinking, answer], cross_validation_instruction)[1]\n    if cross_correct.content == 'False':\n        cot_inputs = [taskInfo, thinking, answer, cross_feedback]\n        thinking, answer = cot_agent(cot_inputs, refinement_instruction)[0], cot_agent(cot_inputs, refinement_instruction)[1]\n\n    # Step 6: Final Answer Synthesis\n    final_synthesis_instruction = 'Given all the insights and feedback, synthesize the final answer.'\n    final_synthesis_agent = LLMAgentBase(['thinking', 'answer'], 'Final Synthesis Agent')\n    final_thinking, final_answer = final_synthesis_agent([taskInfo, thinking, answer], final_synthesis_instruction)[0], final_synthesis_agent([taskInfo, thinking, answer], final_synthesis_instruction)[1]\n\n    return final_answer",
        "fitness": "95% Bootstrap Confidence Interval: (26.9%, 41.9%), Median: 34.4%",
        "generation": 18,
        "acc_list": [
            1,
            1,
            1,
            0,
            0,
            1,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            1,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            1,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            1,
            1,
            0,
            0,
            1,
            0,
            0,
            0,
            1,
            1,
            1,
            1,
            0,
            0,
            1,
            0,
            1,
            0,
            0,
            1,
            0,
            0,
            1,
            0,
            1,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            1,
            1,
            1,
            0,
            0,
            0,
            0,
            1,
            1,
            1,
            1,
            1,
            0,
            1,
            0,
            1,
            0,
            0,
            1,
            0,
            0,
            1,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            1,
            0,
            0,
            0,
            0,
            1,
            0,
            1,
            1,
            1,
            0,
            1,
            0,
            1,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            1,
            0,
            1,
            0,
            0,
            0,
            0,
            0,
            0,
            1,
            0,
            1,
            0,
            0,
            0,
            1,
            1,
            0,
            1,
            1,
            1,
            1,
            1,
            0,
            1,
            0,
            0,
            1,
            0,
            1,
            1,
            0,
            1,
            0,
            1,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            1
        ],
        "cost_list": [
            0.0018900000000000002,
            0.0034835,
            0.012253000000000002,
            0.001875,
            0.0154825,
            0.011287499999999999,
            0.011239500000000005,
            0.007706999999999999,
            0.0043325,
            0.006344999999999999,
            0.005315999999999999,
            0.0103335,
            0.0026144999999999996,
            0.003456499999999999,
            0.0053195000000000004,
            0.011484000000000001,
            0.009974,
            0.013792499999999997,
            0.0129905,
            0.0024584999999999997,
            0.0044434999999999995,
            0.0018795,
            0.004776999999999999,
            0.002367,
            0.009921999999999999,
            0.013685500000000003,
            0.002145,
            0.0110425,
            0.005507500000000001,
            0.0016125000000000002,
            0.003051,
            0.0114395,
            0.004436,
            0.0035349999999999995,
            0.012145000000000003,
            0.0033479999999999994,
            0.014365,
            0.011431500000000004,
            0.011671999999999998,
            0.010273999999999998,
            0.004487499999999999,
            0.0078885,
            0.0049499999999999995,
            0.0090795,
            0.0067995,
            0.00183,
            0.006661500000000001,
            0.010954000000000002,
            0.009946,
            0.0130915,
            0.0176565,
            0.0022349999999999996,
            0.0026444999999999993,
            0.0021615,
            0.009183499999999997,
            0.010542499999999998,
            0.014250499999999996,
            0.011206000000000002,
            0.0037005,
            0.0047434999999999995,
            0.005350500000000001,
            0.0017085,
            0.007993000000000002,
            0.011507000000000002,
            0.0019320000000000001,
            0.005074499999999999,
            0.0125375,
            0.0019830000000000004,
            0.014377499999999996,
            0.011026,
            0.007723999999999999,
            0.003084,
            0.004767,
            0.006632000000000001,
            0.005554000000000001,
            0.010715000000000002,
            0.012650000000000002,
            0.003146999999999999,
            0.008657,
            0.012151999999999998,
            0.009584999999999998,
            0.0130435,
            0.017547000000000007,
            0.005406000000000001,
            0.010207499999999998,
            0.0033049999999999998,
            0.002724,
            0.005888,
            0.013122999999999996,
            0.005393499999999998,
            0.0023145,
            0.006801500000000001,
            0.005421000000000001,
            0.0027955,
            0.007572500000000001,
            0.010145000000000001,
            0.00216,
            0.009231,
            0.011418,
            0.0018074999999999996,
            0.014559499999999998,
            0.0098865,
            0.011033499999999998,
            0.0146015,
            0.004771,
            0.007669999999999999,
            0.007698000000000001,
            0.011035499999999997,
            0.002913,
            0.0047205,
            0.0065545,
            0.0117725,
            0.010135000000000002,
            0.013117,
            0.010306999999999997,
            0.009314000000000003,
            0.004353499999999999,
            0.0017969999999999998,
            0.007063500000000001,
            0.0058925,
            0.010249,
            0.013661499999999997,
            0.0022365,
            0.010979000000000001,
            0.0054505,
            0.0016455000000000003,
            0.007714000000000001,
            0.011015500000000003,
            0.0057335,
            0.006647999999999998,
            0.0122695,
            0.0018210000000000001,
            0.015031000000000004,
            0.010591,
            0.012095499999999995,
            0.010500000000000002,
            0.00442,
            0.006648999999999999,
            0.010373499999999997,
            0.009951499999999999,
            0.002868,
            0.0036695,
            0.0066985,
            0.011647000000000001,
            0.005847499999999999,
            0.0142515,
            0.016561,
            0.0071920000000000005,
            0.00416,
            0.001971,
            0.0024705,
            0.004654,
            0.013007499999999996,
            0.010463999999999998,
            0.002103,
            0.005052999999999999,
            0.0083015,
            0.0042924999999999994,
            0.006643,
            0.009165499999999998
        ]
    }
]