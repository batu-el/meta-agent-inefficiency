[
    {
        "thought": "While an LLM can arrive at the correct answer, its reasoning may vary. By repeatedly asking the same question with high temperature settings, we can generate different reasoning paths. We then combine multiple answers from these Chain-of-Thought (CoT) agents to produce a more accurate final answer through ensembling.",
        "name": "Self-Consistency with Chain-of-Thought",
        "code": "def forward(self, taskInfo):\n    # Instruction for step-by-step reasoning\n    cot_instruction = \"Please think step by step and then solve the task.\"\n    N = 5 # Number of CoT agents\n\n    # Initialize multiple CoT agents with a higher temperature for varied reasoning\n    cot_agents = [LLMAgentBase(['thinking', 'answer'], 'Chain-of-Thought Agent', temperature=0.8) for _ in range(N)]\n\n    # Instruction for final decision-making based on collected reasoning and answers\n    final_decision_instruction = \"Given all the above solutions, reason over them carefully and provide a final answer.\"\n    final_decision_agent = LLMAgentBase(['thinking', 'answer'], 'Final Decision Agent', temperature=0.1)\n    \n    possible_answers = []\n    for i in range(N):\n        thinking, answer = cot_agents[i]([taskInfo], cot_instruction)\n        possible_answers.extend([thinking, answer])\n\n    # Make the final decision based on all generated answers\n    thinking, answer = final_decision_agent([taskInfo] + possible_answers, final_decision_instruction)\n    return answer  \n",
        "generation": "initial",
        "fitness": "95% Bootstrap Confidence Interval: (52.7%, 57.5%), Median: 66.4%",
        "acc_list": [
            100.0,
            100.0,
            77.78,
            0.0,
            0.0,
            0.0,
            0.0,
            100.0,
            100.0,
            66.67,
            100.0,
            100.0,
            100.0,
            80.0,
            100.0,
            0.0,
            32.0,
            0.0,
            100.0,
            100.0,
            0.0,
            0.0,
            100.0,
            0.0,
            100.0,
            26.67,
            100.0,
            100.0,
            30.0,
            80.0,
            100.0,
            94.12,
            33.33,
            100.0,
            0.0,
            100.0,
            100.0,
            0.0,
            100.0,
            0.0,
            0.0,
            100.0,
            0.0,
            59.26,
            100.0,
            100.0,
            100.0,
            100.0,
            0.0,
            66.67,
            66.67,
            66.67,
            100.0,
            100.0,
            100.0,
            50.0,
            100.0,
            22.22,
            100.0,
            0.0,
            100.0,
            0.0,
            85.71,
            0.0,
            100.0,
            0.0,
            0.0,
            100.0,
            0.0,
            100.0,
            100.0,
            100.0,
            66.67,
            0.0,
            100.0,
            0.0,
            100.0,
            100.0,
            57.14,
            0.0,
            100.0,
            0.0,
            84.21,
            66.67,
            88.89,
            100.0,
            100.0,
            54.55,
            100.0,
            66.67,
            100.0,
            0.0,
            100.0,
            100.0,
            100.0,
            0.0,
            100.0,
            100.0,
            100.0,
            0.0,
            32.0,
            100.0,
            100.0,
            0.0,
            100.0,
            100.0,
            71.43,
            100.0,
            66.67,
            100.0,
            100.0,
            100.0,
            66.67,
            66.67,
            100.0,
            100.0,
            100.0,
            100.0,
            100.0,
            46.15,
            15.38,
            100.0,
            0.0,
            100.0,
            100.0,
            100.0,
            0.0,
            100.0
        ],
        "cost_list": [
            0.0021424999999999994,
            0.0026444999999999997,
            0.00304,
            0.002692,
            0.0022825,
            0.0023415,
            0.00206,
            0.002974,
            0.0023605,
            0.0024275,
            0.0023265,
            0.0024745,
            0.00225,
            0.0024874999999999997,
            0.002347,
            0.002534,
            0.0024684999999999998,
            0.005337,
            0.0019109999999999997,
            0.002305,
            0.002352,
            0.0019835,
            0.002231,
            0.0037525,
            0.002883,
            0.002186,
            0.0019655000000000002,
            0.0025614999999999995,
            0.0025304999999999998,
            0.0025035,
            0.0021959999999999996,
            0.002176,
            0.0022415000000000004,
            0.0018254999999999999,
            0.002048,
            0.002294,
            0.0018835,
            0.0019584999999999997,
            0.0024834999999999996,
            0.002025,
            0.002111,
            0.0019060000000000001,
            0.0027584999999999997,
            0.0032655,
            0.0020754999999999997,
            0.0021279999999999997,
            0.0022825,
            0.002648,
            0.0018599999999999999,
            0.002119,
            0.002217,
            0.002102,
            0.001784,
            0.0023805000000000002,
            0.005117999999999999,
            0.0022364999999999998,
            0.0024145,
            0.002547,
            0.0021864999999999996,
            0.002224,
            0.0022665,
            0.002328,
            0.0021824999999999995,
            0.0019099999999999998,
            0.002568,
            0.002137,
            0.002236,
            0.002616,
            0.001987,
            0.0019590000000000002,
            0.002255,
            0.0022015000000000003,
            0.0024865,
            0.0019479999999999999,
            0.0023675,
            0.0021304999999999996,
            0.0020085,
            0.0025930000000000003,
            0.0023305,
            0.002281,
            0.0022379999999999995,
            0.0023005,
            0.0024415,
            0.002052,
            0.0022345,
            0.0019085,
            0.002229,
            0.0023085,
            0.0024575,
            0.002222,
            0.0027719999999999997,
            0.0022685,
            0.0021635,
            0.001866,
            0.0022789999999999998,
            0.0022735000000000003,
            0.002595,
            0.0025705,
            0.0023135000000000005,
            0.002015,
            0.0029005000000000003,
            0.0020204999999999997,
            0.002095,
            0.0022294999999999997,
            0.0024609999999999996,
            0.0025615000000000004,
            0.0028425,
            0.0022240000000000003,
            0.002471,
            0.001902,
            0.002071,
            0.0021165000000000003,
            0.0025635000000000002,
            0.0023245,
            0.0024324999999999998,
            0.00203,
            0.002391,
            0.0019915,
            0.0021509999999999997,
            0.0025195,
            0.002485,
            0.0029514999999999997,
            0.002371,
            0.0019709999999999997,
            0.002474,
            0.002844,
            0.0021755,
            0.001996
        ],
        "test_fitness": "95% Bootstrap Confidence Interval: (54.4%, 58.0%), Median: 65.1%",
        "test_acc_list": [
            100.0,
            0.0,
            100.0,
            100.0,
            26.67,
            0.0,
            100.0,
            0.0,
            66.67,
            66.67,
            100.0,
            100.0,
            100.0,
            0.0,
            100.0,
            100.0,
            100.0,
            100.0,
            100.0,
            0.0,
            100.0,
            100.0,
            0.0,
            100.0,
            0.0,
            90.91,
            60.0,
            100.0,
            0.0,
            100.0,
            100.0,
            100.0,
            100.0,
            100.0,
            100.0,
            100.0,
            90.91,
            0.0,
            100.0,
            0.0,
            100.0,
            100.0,
            0.0,
            100.0,
            100.0,
            100.0,
            100.0,
            66.67,
            100.0,
            100.0,
            0.0,
            100.0,
            100.0,
            66.67,
            0.0,
            66.67,
            100.0,
            21.05,
            100.0,
            100.0,
            0.0,
            100.0,
            66.67,
            33.33,
            0,
            20.0,
            100.0,
            0.0,
            0.0,
            100.0,
            0.0,
            100.0,
            100.0,
            0.0,
            100.0,
            100.0,
            0.0,
            90.91,
            100.0,
            0.0,
            0.0,
            93.33,
            0.0,
            36.36,
            100.0,
            0.0,
            100.0,
            0.0,
            0.0,
            100.0,
            100.0,
            100.0,
            36.36,
            100.0,
            100.0,
            100.0,
            0.0,
            66.67,
            50.0,
            0.0,
            66.67,
            0.0,
            80.0,
            0.0,
            100.0,
            0.0,
            0.0,
            100.0,
            66.67,
            100.0,
            100.0,
            100.0,
            0.0,
            0.0,
            88.89,
            66.67,
            100.0,
            61.54,
            33.33,
            100.0,
            35.29,
            0.0,
            100.0,
            0.0,
            100.0,
            50.0,
            100.0,
            10.53,
            100.0,
            36.36,
            0.0,
            100.0,
            100.0,
            66.67,
            100.0,
            100.0,
            0.0,
            40.0,
            100.0,
            100.0,
            100.0,
            100.0,
            100.0,
            0.0,
            0.0,
            100.0,
            0.0,
            0.0,
            66.67,
            100.0,
            100.0,
            60.0,
            100.0,
            100.0,
            90.91,
            100.0,
            100.0,
            100.0,
            100.0,
            100.0,
            100.0,
            100.0,
            22.22,
            66.67,
            0.0,
            66.67,
            66.67,
            0.0,
            100.0,
            100.0,
            100.0,
            100.0,
            0,
            0.0,
            0.0,
            100.0,
            100.0,
            100.0,
            66.67,
            66.67,
            57.14,
            40.0,
            0.0,
            100.0,
            100.0,
            100.0,
            100.0,
            100.0,
            85.71,
            100.0,
            22.22,
            100.0,
            100.0,
            100.0,
            0.0,
            100.0,
            25.0,
            100.0,
            100.0,
            0.0
        ],
        "test_cost_list": [
            0.0023295,
            0.00228,
            0.002204,
            0.0022605,
            0.0024135,
            0.0023954999999999996,
            0.0024085,
            0.001889,
            0.001971,
            0.00273,
            0.0026079999999999996,
            0.001947,
            0.00221,
            0.002686,
            0.002349,
            0.0021425,
            0.0023854999999999996,
            0.0030165,
            0.0022329999999999997,
            0.0027255,
            0.002428,
            0.0022185,
            0.0021945,
            0.0032115,
            0.0025979999999999996,
            0.0024244999999999996,
            0.00221,
            0.0022695,
            0.002388,
            0.002242,
            0.0019745,
            0.0020059999999999995,
            0.0021165,
            0.0020845,
            0.002806,
            0.002214,
            0.0021395,
            0.0031919999999999995,
            0.0020125,
            0.002167,
            0.0022305,
            0.0022189999999999996,
            0.002382,
            0.0019855,
            0.0020729999999999998,
            0.0022839999999999996,
            0.00247,
            0.002272,
            0.001826,
            0.0029995,
            0.0023334999999999996,
            0.0027045000000000003,
            0.0018104999999999996,
            0.002163,
            0.0024845,
            0.002111,
            0.0020269999999999997,
            0.0024025,
            0.002032,
            0.002103,
            0.002177,
            0.002351,
            0.003085,
            0.002957,
            0.0021924999999999996,
            0.00274,
            0.002362,
            0.0020694999999999997,
            0.0031845,
            0.0019025000000000001,
            0.0024279999999999996,
            0.0022814999999999997,
            0.0022505,
            0.0030745,
            0.002007,
            0.0022425,
            0.0025885,
            0.0019065000000000002,
            0.0026805,
            0.0025965,
            0.0028205,
            0.002477,
            0.0021825,
            0.0026425,
            0.002822,
            0.0024715,
            0.002384,
            0.0023260000000000004,
            0.0019189999999999997,
            0.0025570000000000002,
            0.0019774999999999997,
            0.002223,
            0.002196,
            0.0021019999999999997,
            0.0032239999999999994,
            0.0022719999999999997,
            0.002048,
            0.0021699999999999996,
            0.001864,
            0.0024445,
            0.0029515,
            0.0021739999999999997,
            0.002352,
            0.0025449999999999995,
            0.0021295,
            0.0024725,
            0.0024955,
            0.002249,
            0.0023690000000000004,
            0.0028129999999999995,
            0.0020315,
            0.0023095,
            0.001947,
            0.0023539999999999998,
            0.0024244999999999996,
            0.0027275,
            0.0024200000000000003,
            0.0023415,
            0.0018540000000000002,
            0.0023975,
            0.002456,
            0.0021780000000000002,
            0.0026279999999999997,
            0.0024935,
            0.0023365,
            0.002478,
            0.001982,
            0.0026165,
            0.0019045,
            0.0021514999999999998,
            0.0019645,
            0.0019615,
            0.00223,
            0.00258,
            0.0025859999999999998,
            0.0020199999999999997,
            0.0026664999999999996,
            0.0022364999999999998,
            0.0023439999999999997,
            0.0021934999999999997,
            0.002372,
            0.0024214999999999996,
            0.0025004999999999997,
            0.0019229999999999998,
            0.0028355,
            0.002125,
            0.002587,
            0.002201,
            0.0022765,
            0.0021509999999999997,
            0.0022719999999999997,
            0.0021015,
            0.0028185,
            0.002101,
            0.0018744999999999999,
            0.0024089999999999997,
            0.0020355,
            0.002049,
            0.0030029999999999996,
            0.001862,
            0.0022575,
            0.0023669999999999997,
            0.002284,
            0.0022129999999999997,
            0.0024000000000000002,
            0.0021439999999999996,
            0.0029645,
            0.0031775,
            0.0023220000000000003,
            0.0021509999999999997,
            0.0020085,
            0.0020229999999999996,
            0.0023915,
            0.002382,
            0.0031049999999999997,
            0.0022624999999999998,
            0.0022349999999999996,
            0.002425,
            0.002094,
            0.001944,
            0.0027685,
            0.0028484999999999995,
            0.002541,
            0.0020805,
            0.0022055,
            0.002477,
            0.002837,
            0.0022935,
            0.002133,
            0.002174,
            0.0019795000000000004,
            0.001954,
            0.0024824999999999995,
            0.002569,
            0.0022535000000000003,
            0.0019234999999999999,
            0.00219,
            0.0023095,
            0.002418,
            0.001759
        ]
    },
    {
        "thought": "**Insights:**\nFrom the previous architectures, leveraging multiple expert validations while maintaining a coherent reasoning path can enhance the robustness and accuracy of the final answer. By validating the entire reasoning path in chunks and incorporating iterative refinement, we can streamline the validation process and ensure continuous improvement.\n\n**Overall Idea:**\n1. Generate an initial detailed reasoning path.\n2. Validate the reasoning path in chunks using multiple expert agents.\n3. Incorporate feedback from the final decision agent for iterative refinement.\n4. Iterate until convergence or a maximum number of iterations is reached.\n5. Aggregate the final refined reasoning paths into a coherent answer.\n\n**Implementation:**\n1. Use an initial agent to generate a detailed reasoning path.\n2. Split the reasoning path into chunks and validate each chunk using multiple expert agents.\n3. Use a final decision agent to review and provide feedback on the combined reasoning path.\n4. Iterate the validation and feedback process until convergence or a maximum number of iterations is reached.\n5. Aggregate the final refined reasoning paths into a coherent answer.",
        "name": "Iterative Chunk Validation",
        "code": "def forward(self, taskInfo):\n    # Instruction for generating the initial detailed reasoning path\n    initial_instruction = \"Please think step by step and then solve the task with a detailed reasoning path.\"\n    initial_agent = LLMAgentBase(['thinking', 'reasoning_path'], 'Initial Reasoning Agent')\n\n    # Instruction for validating each chunk of reasoning path based on role-specific expertise\n    validation_instruction_template = \"Given the following reasoning chunk: '{reasoning_chunk}', please validate it based on your expertise in {role}.\"\n    roles = ['Reading Comprehension', 'Logical Reasoning', 'Multidisciplinary Integration']\n    validation_agents = [LLMAgentBase(['thinking', 'validated_chunk'], f'{role} Specialist') for role in roles]\n\n    # Instruction for final decision-making based on the combined reasoning paths\n    final_decision_instruction = \"Given all the above thinking and validated chunks, reason over them carefully and provide a final answer.\"\n    final_decision_agent = LLMAgentBase(['thinking', 'answer'], 'Final Decision Agent', temperature=0.1)\n\n    # Generate the initial detailed reasoning path\n    initial_thinking, initial_reasoning_path = initial_agent([taskInfo], initial_instruction)\n\n    # Split the reasoning path into chunks (e.g., paragraphs or logical segments)\n    reasoning_chunks = initial_reasoning_path.content.split('. ')\n\n    # Initialize list to store validated chunks\n    validated_chunks = []\n\n    # Maximum number of iterations for refinement\n    N_max = 5\n\n    for i in range(N_max):\n        for chunk in reasoning_chunks:\n            chunk_validations = []\n            for role, agent in zip(roles, validation_agents):\n                validation_instruction = validation_instruction_template.format(reasoning_chunk=chunk, role=role)\n                thinking, validated_chunk = agent([taskInfo, Info('reasoning_chunk', 'Initial Reasoning Agent', chunk, -1)], validation_instruction)\n                chunk_validations.append(validated_chunk)\n\n            # Aggregate validated chunks\n            aggregated_chunk = Info('validated_chunk', 'Aggregator', ' '.join([v_chunk.content for v_chunk in chunk_validations]), -1)\n            validated_chunks.append(aggregated_chunk)\n\n        # Combine the validated chunks into a coherent final reasoning path\n        combined_reasoning_infos = [Info('validated_path', 'Combiner', ' '.join([chunk.content for chunk in validated_chunks]), -1)]\n\n        # Get feedback from the final decision agent\n        thinking, answer = final_decision_agent([taskInfo, initial_thinking] + combined_reasoning_infos, final_decision_instruction)\n\n        # If the final decision agent indicates correctness, break the loop\n        feedback_info = final_decision_agent([taskInfo, initial_thinking] + combined_reasoning_infos, final_decision_instruction)\n        if any(info.content.lower() == 'true' for info in feedback_info):\n            break\n\n        # Update the initial reasoning path with feedback\n        initial_reasoning_path = combined_reasoning_infos[-1]\n\n    return answer\n",
        "fitness": "95% Bootstrap Confidence Interval: (59.5%, 63.7%), Median: 72.3%",
        "generation": 3,
        "acc_list": [
            100.0,
            33.33,
            100.0,
            100.0,
            0.0,
            100.0,
            100.0,
            100.0,
            100.0,
            66.67,
            100.0,
            100.0,
            100.0,
            80.0,
            100.0,
            100.0,
            61.54,
            0.0,
            100.0,
            100.0,
            0.0,
            0.0,
            100.0,
            16.67,
            100.0,
            100.0,
            100.0,
            100.0,
            100.0,
            80.0,
            100.0,
            94.12,
            100.0,
            0.0,
            0.0,
            0.0,
            100.0,
            0.0,
            100.0,
            0.0,
            0.0,
            100.0,
            100.0,
            72.73,
            100.0,
            100.0,
            100.0,
            16.67,
            100.0,
            66.67,
            66.67,
            100.0,
            100.0,
            100.0,
            100.0,
            50.0,
            100.0,
            100.0,
            100.0,
            0.0,
            100.0,
            40.0,
            85.71,
            0.0,
            0.0,
            100.0,
            0.0,
            100.0,
            100.0,
            100.0,
            100.0,
            0.0,
            66.67,
            100.0,
            100.0,
            100.0,
            66.67,
            100.0,
            75.0,
            0.0,
            100.0,
            0.0,
            84.21,
            100.0,
            88.89,
            100.0,
            100.0,
            42.86,
            100.0,
            100.0,
            100.0,
            0.0,
            100.0,
            100.0,
            100.0,
            100.0,
            100.0,
            66.67,
            100.0,
            0.0,
            0.0,
            20.0,
            100.0,
            0.0,
            100.0,
            100.0,
            90.91,
            0.0,
            100.0,
            0.0,
            100.0,
            100.0,
            100.0,
            100.0,
            100.0,
            100.0,
            100.0,
            100.0,
            30.77,
            46.15,
            50.0,
            100.0,
            0.0,
            100.0,
            100.0,
            66.67,
            22.22,
            100.0
        ],
        "cost_list": [
            0.039813,
            0.08603800000000002,
            0.0565315,
            0.06261299999999999,
            0.04233,
            0.024106999999999996,
            0.020778,
            0.07138749999999999,
            0.06043099999999999,
            0.047241500000000006,
            0.046217,
            0.033127500000000004,
            0.033555,
            0.07184000000000001,
            0.035886499999999995,
            0.03554,
            0.04543100000000002,
            0.12304649999999995,
            0.027165999999999996,
            0.040076499999999994,
            0.07828349999999999,
            0.029102999999999997,
            0.05209,
            0.07832699999999997,
            0.0483025,
            0.037441,
            0.06041499999999998,
            0.04184399999999999,
            0.05884850000000003,
            0.03523949999999999,
            0.03165149999999999,
            0.08872700000000001,
            0.04703499999999999,
            0.022954499999999996,
            0.039781,
            0.034705,
            0.0192105,
            0.04164849999999997,
            0.0498545,
            0.018304999999999995,
            0.048415,
            0.021192000000000006,
            0.06990049999999999,
            0.06099400000000003,
            0.04529449999999999,
            0.0316575,
            0.023968500000000007,
            0.03457999999999999,
            0.033272,
            0.039922500000000014,
            0.030890000000000008,
            0.033213000000000006,
            0.028406999999999995,
            0.04187999999999999,
            0.064288,
            0.0701115,
            0.05905100000000001,
            0.0314265,
            0.0355245,
            0.09068799999999995,
            0.03959300000000002,
            0.012377,
            0.05784500000000002,
            0.0228,
            0.0548385,
            0.051038500000000014,
            0.0329355,
            0.07012049999999999,
            0.04448349999999999,
            0.022372500000000007,
            0.03679450000000001,
            0.030120999999999995,
            0.04227999999999999,
            0.0260835,
            0.023748000000000005,
            0.033020999999999995,
            0.04125449999999999,
            0.05784449999999999,
            0.04154749999999999,
            0.04292149999999998,
            0.04184449999999999,
            0.04117200000000001,
            0.04002049999999999,
            0.024029000000000005,
            0.039953,
            0.0313285,
            0.04526199999999999,
            0.04527399999999998,
            0.05683749999999997,
            0.030706,
            0.08837100000000005,
            0.04889199999999999,
            0.03887149999999999,
            0.029605500000000007,
            0.042883500000000005,
            0.020738999999999994,
            0.042377000000000005,
            0.033646499999999996,
            0.0406565,
            0.027962500000000005,
            0.06010249999999999,
            0.04051200000000001,
            0.023402999999999993,
            0.047518,
            0.03918300000000001,
            0.06409199999999995,
            0.058691,
            0.0325955,
            0.042663,
            0.04851949999999999,
            0.033316500000000006,
            0.031800499999999995,
            0.06998099999999996,
            0.03045549999999999,
            0.03477050000000001,
            0.021351499999999995,
            0.02858749999999999,
            0.03575549999999999,
            0.04438050000000003,
            0.0206545,
            0.04172699999999999,
            0.062234,
            0.06731450000000001,
            0.03462799999999999,
            0.04419050000000001,
            0.056441999999999964,
            0.028936499999999993,
            0.04533249999999999
        ],
        "test_fitness": "95% Bootstrap Confidence Interval: (59.2%, 63.0%), Median: 70.1%",
        "test_acc_list": [
            100.0,
            0.0,
            100.0,
            100.0,
            100.0,
            100.0,
            100.0,
            42.11,
            100.0,
            66.67,
            100.0,
            0.0,
            100.0,
            100.0,
            100.0,
            100.0,
            100.0,
            100.0,
            25.0,
            0.0,
            100.0,
            100.0,
            0.0,
            0.0,
            100.0,
            50.0,
            85.71,
            100.0,
            0.0,
            100.0,
            100.0,
            100.0,
            100.0,
            100.0,
            100.0,
            100.0,
            55.56,
            0.0,
            100.0,
            0.0,
            100.0,
            0.0,
            0.0,
            100.0,
            100.0,
            100.0,
            100.0,
            0.0,
            100.0,
            100.0,
            100.0,
            33.33,
            100.0,
            100.0,
            0.0,
            0.0,
            100.0,
            21.05,
            100.0,
            100.0,
            0.0,
            100.0,
            0.0,
            100.0,
            100.0,
            20.0,
            100.0,
            100.0,
            0.0,
            100.0,
            0.0,
            13.33,
            100.0,
            0.0,
            100.0,
            20.0,
            0.0,
            90.91,
            100.0,
            18.18,
            0.0,
            93.33,
            11.11,
            100.0,
            100.0,
            0.0,
            100.0,
            0.0,
            0.0,
            100.0,
            100.0,
            100.0,
            100.0,
            100.0,
            100.0,
            100.0,
            100.0,
            0.0,
            100.0,
            100.0,
            100.0,
            100.0,
            61.54,
            0.0,
            28.57,
            100.0,
            0.0,
            100.0,
            100.0,
            100.0,
            66.67,
            100.0,
            100.0,
            0.0,
            100.0,
            0.0,
            100.0,
            53.33,
            100.0,
            100.0,
            30.0,
            10.0,
            100.0,
            100.0,
            100.0,
            100.0,
            100.0,
            0.0,
            100.0,
            100.0,
            0.0,
            100.0,
            100.0,
            0.0,
            100.0,
            100.0,
            20.0,
            40.0,
            100.0,
            100.0,
            100.0,
            100.0,
            100.0,
            100.0,
            100.0,
            100.0,
            100.0,
            0.0,
            100.0,
            100.0,
            100.0,
            100.0,
            100.0,
            100.0,
            0.0,
            100.0,
            100.0,
            100.0,
            100.0,
            100.0,
            100.0,
            50.0,
            18.18,
            0.0,
            0.0,
            66.67,
            100.0,
            0.0,
            100.0,
            100.0,
            100.0,
            0.0,
            16.67,
            100.0,
            0.0,
            100.0,
            100.0,
            100.0,
            66.67,
            100.0,
            26.67,
            40.0,
            0.0,
            100.0,
            100.0,
            100.0,
            100.0,
            100.0,
            85.71,
            0.0,
            100.0,
            100.0,
            100.0,
            100.0,
            0.0,
            100.0,
            25.0,
            100.0,
            66.67,
            100.0
        ],
        "test_cost_list": [
            0.05576399999999997,
            0.048251,
            0.03160450000000001,
            0.03528699999999999,
            0.031502999999999996,
            0.039598,
            0.032275500000000006,
            0.053710500000000015,
            0.04122049999999999,
            0.035343000000000006,
            0.029927500000000003,
            0.03764200000000001,
            0.04863400000000001,
            0.05757150000000001,
            0.017724,
            0.029881500000000005,
            0.034469000000000014,
            0.05309399999999998,
            0.030420999999999997,
            0.02836450000000001,
            0.0527415,
            0.013741500000000002,
            0.0411305,
            0.041788999999999986,
            0.056408000000000035,
            0.041617499999999995,
            0.02974100000000001,
            0.036945000000000006,
            0.040211000000000004,
            0.043047,
            0.019205,
            0.033756,
            0.011326,
            0.018573500000000003,
            0.049617999999999995,
            0.040223499999999995,
            0.049448,
            0.0625555,
            0.03104549999999999,
            0.030624500000000002,
            0.055438999999999995,
            0.03992149999999999,
            0.07285199999999997,
            0.019556,
            0.02479200000000001,
            0.028167499999999998,
            0.05549499999999999,
            0.04343700000000002,
            0.014662000000000001,
            0.084163,
            0.043509500000000007,
            0.06938400000000002,
            0.009825000000000002,
            0.064227,
            0.03439149999999999,
            0.0321295,
            0.028751499999999985,
            0.035207999999999996,
            0.029406,
            0.03507499999999999,
            0.024373000000000002,
            0.040885999999999985,
            0.0765395,
            0.053485499999999984,
            0.0548885,
            0.04871500000000001,
            0.04326499999999997,
            0.0430585,
            0.033419000000000004,
            0.028519499999999996,
            0.04656249999999998,
            0.04366650000000001,
            0.04157699999999999,
            0.047362999999999995,
            0.021889,
            0.028772999999999993,
            0.12261900000000003,
            0.030679499999999995,
            0.07335049999999997,
            0.10012549999999991,
            0.0295945,
            0.033245000000000004,
            0.040853499999999994,
            0.0587515,
            0.08566150000000003,
            0.043696,
            0.03531000000000001,
            0.05983350000000002,
            0.022729000000000003,
            0.037529000000000014,
            0.026236999999999996,
            0.0493365,
            0.040748,
            0.010189,
            0.0431955,
            0.04122199999999998,
            0.038819000000000006,
            0.04296349999999998,
            0.05765049999999995,
            0.044750500000000006,
            0.03871950000000001,
            0.0395665,
            0.05548699999999998,
            0.033572,
            0.023654,
            0.04850249999999999,
            0.05312500000000002,
            0.04912749999999999,
            0.04866849999999999,
            0.035329500000000014,
            0.02793549999999999,
            0.04895350000000003,
            0.025450999999999998,
            0.048722000000000015,
            0.0333915,
            0.04939199999999997,
            0.03317850000000001,
            0.10700549999999998,
            0.0370375,
            0.08300449999999998,
            0.05015450000000001,
            0.05217500000000002,
            0.05123200000000001,
            0.06699849999999999,
            0.027511999999999995,
            0.04776999999999998,
            0.05952149999999998,
            0.054393999999999984,
            0.028047000000000002,
            0.04698649999999999,
            0.021466500000000003,
            0.02700300000000001,
            0.026577500000000004,
            0.07276350000000002,
            0.052629000000000016,
            0.030521999999999997,
            0.055723999999999975,
            0.0748405,
            0.0351555,
            0.03379499999999999,
            0.05756650000000002,
            0.051317499999999995,
            0.04131349999999998,
            0.027048,
            0.05475400000000001,
            0.0235755,
            0.03626899999999999,
            0.048907500000000034,
            0.052189500000000014,
            0.0431115,
            0.04496349999999999,
            0.038695499999999994,
            0.03879150000000001,
            0.03822200000000002,
            0.028339999999999997,
            0.0406245,
            0.03941600000000001,
            0.027139999999999997,
            0.05845499999999998,
            0.03952350000000002,
            0.025043999999999997,
            0.04828749999999998,
            0.0275355,
            0.03688200000000001,
            0.0347185,
            0.06142499999999998,
            0.07229650000000003,
            0.09412100000000001,
            0.03349449999999999,
            0.031608500000000005,
            0.0283975,
            0.03959799999999999,
            0.0320165,
            0.0238865,
            0.03342050000000001,
            0.0190755,
            0.032042,
            0.0468745,
            0.042301000000000005,
            0.0357525,
            0.04648500000000002,
            0.07728799999999998,
            0.0203425,
            0.034325999999999995,
            0.025837500000000003,
            0.06310450000000004,
            0.039337499999999984,
            0.0209775,
            0.04665799999999999,
            0.06698649999999998,
            0.03357649999999999,
            0.011443,
            0.04737950000000001,
            0.06127350000000001,
            0.03265549999999999,
            0.05206699999999999,
            0.028107500000000018,
            0.033450499999999994,
            0.041215499999999974,
            0.020245499999999996
        ]
    }
]