[
    {
        "thought": "Similar to Quality-Diversity methods, let LLM generate multiple diverse interesting solutions could help. By encouraging the model to explore different reasoning paths, we can increase the chances of finding the best solution.",
        "name": "Quality-Diversity",
        "code": "def forward(self, taskInfo):\n    # Instruction for initial reasoning\n    cot_initial_instruction = \"Please think step by step and then solve the task.\"\n\n    # Instruction for giving diverse answers\n    qd_instruction = \"Given previous attempts, try to come up with another interesting way to solve the task.\"\n    cot_agent = LLMAgentBase(['thinking', 'answer'], 'Chain-of-Thought Agent')\n\n    # Instruction for final decision-making based on collected reasoning and answers\n    final_decision_instruction = \"Given all the above solutions, reason over them carefully and provide a final answer.\"\n    final_decision_agent = LLMAgentBase(['thinking', 'answer'], 'Final Decision Agent', temperature=0.1)\n    \n    N_max = 3 # Maximum number of attempts\n\n    # Initial attempt\n    cot_inputs = [taskInfo]\n    possible_answers = []\n    thinking, answer = cot_agent(cot_inputs, cot_initial_instruction, 0)\n\n    # Add the answer to the list of possible answers\n    possible_answers.extend([thinking, answer])\n\n    for i in range(N_max):\n        # Reflect on previous attempts and generate another interesting answer\n        cot_inputs.extend([thinking, answer])\n\n        # Generate another interesting answer\n        thinking, answer = cot_agent(cot_inputs, qd_instruction, i + 1)\n        possible_answers.extend([thinking, answer])\n\n    # Make the final decision based on all generated answers\n    thinking, answer = final_decision_agent([taskInfo] + possible_answers, final_decision_instruction)\n    return answer\n",
        "generation": "initial",
        "fitness": "95% Bootstrap Confidence Interval: (56.1%, 60.6%), Median: 69.4%",
        "acc_list": [
            100.0,
            100.0,
            100.0,
            0.0,
            0.0,
            66.67,
            100.0,
            100.0,
            100.0,
            100.0,
            100.0,
            100.0,
            100.0,
            80.0,
            100.0,
            0.0,
            29.63,
            100.0,
            100.0,
            100.0,
            0.0,
            0.0,
            100.0,
            100.0,
            66.67,
            0.0,
            100.0,
            100.0,
            30.0,
            80.0,
            100.0,
            94.12,
            100.0,
            100.0,
            0.0,
            0.0,
            100.0,
            100.0,
            100.0,
            0.0,
            0.0,
            100.0,
            0.0,
            72.73,
            100.0,
            100.0,
            16.67,
            15.38,
            100.0,
            66.67,
            33.33,
            66.67,
            100.0,
            100.0,
            100.0,
            50.0,
            0.0,
            50.0,
            100.0,
            0.0,
            100.0,
            0.0,
            85.71,
            0.0,
            66.67,
            0.0,
            0.0,
            33.33,
            100.0,
            100.0,
            100.0,
            0.0,
            66.67,
            100.0,
            100.0,
            0.0,
            100.0,
            100.0,
            75.0,
            0.0,
            100.0,
            0.0,
            76.19,
            100.0,
            100.0,
            100.0,
            100.0,
            100.0,
            100.0,
            66.67,
            0.0,
            0.0,
            100.0,
            100.0,
            100.0,
            0.0,
            100.0,
            66.67,
            100.0,
            0.0,
            24.0,
            100.0,
            100.0,
            0.0,
            100.0,
            100.0,
            90.91,
            100.0,
            66.67,
            100.0,
            100.0,
            100.0,
            100.0,
            100.0,
            100.0,
            100.0,
            100.0,
            100.0,
            100.0,
            50.0,
            18.18,
            100.0,
            0.0,
            100.0,
            100.0,
            66.67,
            100.0,
            100.0
        ],
        "cost_list": [
            0.002055,
            0.0023395,
            0.0027119999999999996,
            0.002374,
            0.002097,
            0.0022015,
            0.001965,
            0.002745,
            0.002153,
            0.0021219999999999998,
            0.0020745,
            0.0023495,
            0.0020605,
            0.0023435,
            0.0020434999999999997,
            0.0024059999999999997,
            0.0021780000000000002,
            0.0046605,
            0.0017929999999999999,
            0.002137,
            0.0020664999999999998,
            0.0019965,
            0.0020885,
            0.0031904999999999998,
            0.002623,
            0.0019129999999999998,
            0.001827,
            0.002315,
            0.0025204999999999997,
            0.002326,
            0.0020145,
            0.0021115,
            0.0020215,
            0.001762,
            0.0018445,
            0.0022975,
            0.0018529999999999998,
            0.0018605000000000002,
            0.002293,
            0.0018729999999999999,
            0.0020020000000000003,
            0.001822,
            0.0024939999999999997,
            0.0029844999999999997,
            0.002109,
            0.0019519999999999997,
            0.0023175,
            0.002589,
            0.001866,
            0.001849,
            0.0021995,
            0.0020275,
            0.0016695,
            0.002129,
            0.004449,
            0.0020359999999999996,
            0.002281,
            0.0020365,
            0.001996,
            0.002216,
            0.002098,
            0.0021545,
            0.0021,
            0.0018925,
            0.0022259999999999997,
            0.0020815,
            0.0020745,
            0.0024339999999999995,
            0.001846,
            0.0016495,
            0.002136,
            0.001988,
            0.0023185,
            0.0018345,
            0.0021855,
            0.002201,
            0.0018159999999999997,
            0.002336,
            0.002237,
            0.0021314999999999997,
            0.0019855,
            0.002137,
            0.0023045,
            0.002007,
            0.0020345,
            0.0018840000000000003,
            0.001997,
            0.0020145,
            0.0022265,
            0.0020675,
            0.002485,
            0.0020345,
            0.0019815,
            0.001738,
            0.0020564999999999997,
            0.002168,
            0.0023525,
            0.0022884999999999997,
            0.0019744999999999997,
            0.0019294999999999996,
            0.0027814999999999997,
            0.0018249999999999998,
            0.002032,
            0.0019785000000000002,
            0.0021809999999999998,
            0.0024235,
            0.002473,
            0.0020495,
            0.0023144999999999997,
            0.0017975,
            0.0018939999999999999,
            0.0019045,
            0.0022944999999999997,
            0.0020794999999999998,
            0.0023404999999999997,
            0.0019199999999999998,
            0.0022170000000000002,
            0.0019415,
            0.0020115,
            0.0022405,
            0.0022045,
            0.0026479999999999997,
            0.0021995,
            0.0019199999999999998,
            0.002229,
            0.002521,
            0.002089,
            0.001823
        ],
        "test_fitness": "95% Bootstrap Confidence Interval: (52.4%, 56.2%), Median: 63.7%",
        "test_acc_list": [
            100.0,
            0.0,
            100.0,
            100.0,
            33.33,
            0.0,
            100.0,
            0.0,
            66.67,
            0.0,
            100.0,
            100.0,
            100.0,
            0.0,
            100.0,
            100.0,
            100.0,
            0.0,
            100.0,
            0.0,
            100.0,
            100.0,
            100.0,
            100.0,
            0.0,
            90.91,
            47.06,
            100.0,
            0.0,
            100.0,
            100.0,
            100.0,
            100.0,
            100.0,
            33.33,
            100.0,
            44.44,
            100.0,
            0.0,
            0.0,
            100.0,
            100.0,
            0.0,
            0.0,
            0.0,
            100.0,
            100.0,
            100.0,
            100.0,
            100.0,
            100.0,
            100.0,
            100.0,
            100.0,
            0.0,
            66.67,
            100.0,
            30.77,
            100.0,
            100.0,
            0.0,
            100.0,
            66.67,
            100.0,
            0.0,
            20.0,
            100.0,
            0.0,
            0.0,
            100.0,
            0.0,
            0.0,
            36.36,
            0.0,
            100.0,
            100.0,
            100.0,
            90.91,
            100.0,
            0.0,
            0.0,
            93.33,
            0.0,
            100.0,
            100.0,
            0.0,
            100.0,
            0.0,
            0.0,
            100.0,
            0.0,
            100.0,
            44.44,
            100.0,
            100.0,
            100.0,
            0.0,
            0.0,
            100.0,
            0.0,
            100.0,
            0.0,
            80.0,
            0.0,
            100.0,
            0.0,
            0.0,
            100.0,
            100.0,
            14.29,
            100.0,
            100.0,
            100.0,
            0.0,
            88.89,
            100.0,
            100.0,
            66.67,
            100.0,
            40.0,
            35.29,
            0.0,
            100.0,
            80.0,
            100.0,
            0.0,
            100.0,
            7.41,
            100.0,
            30.77,
            100.0,
            100.0,
            100.0,
            0.0,
            100.0,
            100.0,
            18.18,
            0.0,
            100.0,
            100.0,
            100.0,
            60.0,
            100.0,
            100.0,
            0.0,
            100.0,
            100.0,
            0.0,
            66.67,
            100.0,
            100.0,
            100.0,
            100.0,
            100.0,
            0.0,
            100.0,
            100.0,
            100.0,
            100.0,
            100.0,
            0.0,
            100.0,
            66.67,
            100.0,
            0.0,
            66.67,
            100.0,
            0.0,
            100.0,
            0.0,
            40.0,
            100.0,
            20.0,
            100.0,
            0.0,
            100.0,
            100.0,
            100.0,
            57.14,
            100.0,
            66.67,
            40.0,
            0.0,
            100.0,
            100.0,
            100.0,
            100.0,
            0.0,
            100.0,
            40.0,
            22.22,
            100.0,
            28.57,
            0.0,
            0.0,
            100.0,
            25.0,
            100.0,
            100.0,
            0.0
        ],
        "test_cost_list": [
            0.0021655,
            0.002183,
            0.0020005,
            0.0019595,
            0.002259,
            0.0022500000000000003,
            0.0021145,
            0.001755,
            0.0018515,
            0.0024805,
            0.0022494999999999998,
            0.0017695,
            0.001999,
            0.0024194999999999998,
            0.0021555,
            0.001985,
            0.0021885,
            0.0026195,
            0.0019995,
            0.0025675,
            0.0021160000000000003,
            0.00202,
            0.0020825,
            0.0028689999999999996,
            0.0024035,
            0.0021995,
            0.002137,
            0.0021245,
            0.002256,
            0.0020715,
            0.0018509999999999998,
            0.00184,
            0.0020215,
            0.0018775,
            0.0026575,
            0.0019944999999999997,
            0.002005,
            0.0027719999999999997,
            0.0019,
            0.002004,
            0.002034,
            0.002071,
            0.002152,
            0.0018225,
            0.0019065,
            0.002002,
            0.0022494999999999998,
            0.00217,
            0.0017339999999999999,
            0.0028209999999999997,
            0.002131,
            0.0024275,
            0.0017720000000000001,
            0.00199,
            0.0024159999999999997,
            0.0019494999999999998,
            0.0018165,
            0.002104,
            0.0019215,
            0.0018724999999999998,
            0.0020829999999999998,
            0.0021335,
            0.0027245000000000004,
            0.002637,
            0.002021,
            0.0026709999999999998,
            0.002091,
            0.0019394999999999998,
            0.002837,
            0.0018009999999999999,
            0.0021785,
            0.0021149999999999997,
            0.002202,
            0.002813,
            0.0018574999999999998,
            0.002064,
            0.002395,
            0.001873,
            0.002319,
            0.0022335,
            0.002502,
            0.0022245,
            0.001941,
            0.0023769999999999998,
            0.0025275000000000002,
            0.0021115,
            0.002245,
            0.002286,
            0.001779,
            0.002372,
            0.001936,
            0.0020469999999999998,
            0.0019825,
            0.001993,
            0.0027355,
            0.0020645,
            0.0020784999999999996,
            0.002006,
            0.0017850000000000001,
            0.0022395,
            0.002727,
            0.001885,
            0.0022215,
            0.0022449999999999996,
            0.0019070000000000003,
            0.002311,
            0.002306,
            0.002133,
            0.002079,
            0.0025895,
            0.00197,
            0.0020724999999999997,
            0.0018235,
            0.0022405000000000003,
            0.002239,
            0.0024609999999999996,
            0.0021525,
            0.0020684999999999996,
            0.0017825,
            0.002217,
            0.002298,
            0.0019715,
            0.0024409999999999996,
            0.0022965,
            0.0021195,
            0.002226,
            0.001934,
            0.0027244999999999995,
            0.001774,
            0.002009,
            0.0018995000000000001,
            0.0017894999999999999,
            0.00204,
            0.0023474999999999998,
            0.0023315,
            0.0017835,
            0.0024539999999999996,
            0.0020195,
            0.002136,
            0.0019944999999999997,
            0.0021435,
            0.0024235000000000003,
            0.0023125,
            0.0018675000000000002,
            0.002537,
            0.002003,
            0.0023205,
            0.002147,
            0.0021555,
            0.0020035,
            0.0020575,
            0.0018805,
            0.0025864999999999994,
            0.0019775,
            0.0017329999999999997,
            0.0021704999999999997,
            0.0018569999999999997,
            0.001906,
            0.002707,
            0.001862,
            0.002087,
            0.0021605,
            0.0019405,
            0.00206,
            0.0022045,
            0.0020085,
            0.0027995,
            0.0028665,
            0.0021085,
            0.0020295,
            0.001862,
            0.0019405,
            0.0021795,
            0.0021935,
            0.002813,
            0.00221,
            0.001973,
            0.0021244999999999997,
            0.0019075000000000001,
            0.001798,
            0.0024135000000000003,
            0.0026435,
            0.0023165,
            0.0019285,
            0.0020035,
            0.0021734999999999997,
            0.0025534999999999998,
            0.0022294999999999997,
            0.0019795,
            0.0019494999999999998,
            0.0019855,
            0.0017385,
            0.0023759999999999996,
            0.0022645,
            0.001962,
            0.0017944999999999999,
            0.0019979999999999998,
            0.0021945,
            0.002084,
            0.0016904999999999997
        ]
    },
    {
        "thought": "**Insights:**\nIncorporating layered validation checks at each step can significantly enhance the accuracy and reliability of the agent's outputs. Additionally, integrating self-explanation with the reasoning process and introducing a dynamic feedback loop can provide a more cohesive and adaptive reasoning mechanism. This approach will ensure the agent adapts its strategies based on real-time feedback and provides high-quality, explainable answers.\n\n**Overall Idea:**\nThe proposed agent will use a layered validation approach where each strategy's output is validated and refined iteratively. The self-explanation mechanism will be integrated with the reasoning process to provide deeper insights and identify potential errors. A dynamic feedback loop will be introduced to adapt strategies based on task complexity and performance metrics. The memory mechanism will be updated dynamically during the reasoning process to ensure cohesive integration of past experiences.\n\n**Implementation:**\n1. **Task Decomposition:** Decompose the task into high-level strategies.\n2. **Initial Reasoning:** Use diverse strategies (Chain-of-Thought, Self-Refine, Debate) to generate initial answers.\n3. **Self-Explanation:** Require the agent to explain its reasoning during the reasoning process.\n4. **Layered Validation Checks:** Validate the outputs of each strategy and integrate feedback iteratively.\n5. **Dynamic Feedback Loop:** Adjust strategies based on performance metrics and feedback.\n6. **Dynamic Memory Update:** Update memory dynamically during the reasoning process.\n7. **Final Decision:** Synthesize insights from all iterations, explanations, and validations to provide the final answer.",
        "name": "Layered Validation Adaptive Agent",
        "code": "def forward(self, taskInfo):\n    # Step 1: Task Decomposition into high-level strategies\n    decomposition_instruction = 'Please decompose the task into high-level strategies that can be handled by different specialized agents.'\n    decomposition_agent = LLMAgentBase(['strategies'], 'Decomposition Agent')\n    strategies_info = decomposition_agent([taskInfo], decomposition_instruction, 0)\n\n    # Step 2: Initial Reasoning using diverse strategies\n    cot_instruction = 'Please think step by step and then solve the task.'\n    self_refine_instruction = 'Please reflect on your previous attempt and refine your answer.'\n    debate_instruction = 'Please debate with other agents and provide an answer to the task.'\n    cot_agent = LLMAgentBase(['thinking', 'answer'], 'Chain-of-Thought Agent')\n    self_refine_agent = LLMAgentBase(['thinking', 'answer'], 'Self-Refine Agent')\n    debate_agent = LLMAgentBase(['thinking', 'answer'], 'Debate Agent')\n    initial_responses = []\n\n    cot_thinking, cot_answer = cot_agent([taskInfo], cot_instruction, 0)\n    self_refine_thinking, self_refine_answer = self_refine_agent([taskInfo], self_refine_instruction, 0)\n    debate_thinking, debate_answer = debate_agent([taskInfo], debate_instruction, 0)\n\n    initial_responses.extend([cot_thinking, cot_answer, self_refine_thinking, self_refine_answer, debate_thinking, debate_answer])\n\n    # Step 3: Self-Explanation during reasoning\n    explanation_instruction = 'Explain your reasoning and answer step by step during the reasoning process.'\n    explanation_agent = LLMAgentBase(['reasoning_explanation'], 'Explanation Agent')\n    explanations = []\n    for response in initial_responses:\n        explanations.extend(explanation_agent([taskInfo, response], explanation_instruction, 0))\n\n    # Step 4: Layered Validation Checks\n    validation_instruction = 'Validate the provided answers and explanations, and identify any potential errors. Provide feedback for improvement.'\n    validation_agent = LLMAgentBase(['feedback', 'errors'], 'Validation Agent')\n    feedback, errors = validation_agent([taskInfo] + initial_responses + explanations, validation_instruction, 1)\n\n    # Step 5: Dynamic Feedback Loop\n    feedback_loop_instruction = 'Using performance metrics and feedback, dynamically adjust the strategies and refine the answers.'\n    feedback_loop_agent = LLMAgentBase(['thinking', 'adjusted_strategies'], 'Feedback Loop Agent')\n    thinking, adjusted_strategies = feedback_loop_agent([taskInfo] + initial_responses + explanations + [feedback, errors], feedback_loop_instruction, 2)\n\n    # Step 6: Dynamic Memory Update\n    memory_update_instruction = 'Update the memory dynamically during the reasoning process based on new insights.'\n    memory_update_agent = LLMAgentBase(['updated_memory'], 'Memory Update Agent')\n    updated_memory = memory_update_agent([taskInfo] + initial_responses + explanations + [feedback, errors, thinking], memory_update_instruction, 3)\n\n    # Step 7: Final Decision\n    final_decision_instruction = 'Based on the refined answers, explanations, and memory, provide the final answer to the task.'\n    final_decision_agent = LLMAgentBase(['thinking', 'final_answer'], 'Final Decision Agent')\n    thinking, final_answer = final_decision_agent([taskInfo] + initial_responses + explanations + [feedback, errors, updated_memory], final_decision_instruction, 4)\n\n    return final_answer\n",
        "fitness": "95% Bootstrap Confidence Interval: (60.5%, 64.5%), Median: 72.9%",
        "generation": 18,
        "acc_list": [
            100.0,
            100.0,
            100.0,
            100.0,
            66.67,
            100.0,
            0.0,
            100.0,
            100.0,
            100.0,
            100.0,
            16.67,
            100.0,
            80.0,
            100.0,
            0.0,
            29.63,
            0.0,
            100.0,
            66.67,
            100.0,
            100.0,
            100.0,
            16.67,
            100.0,
            100.0,
            100.0,
            100.0,
            30.0,
            100.0,
            100.0,
            94.12,
            100.0,
            100.0,
            0.0,
            0.0,
            100.0,
            100.0,
            100.0,
            0.0,
            66.67,
            100.0,
            100.0,
            72.73,
            100.0,
            100.0,
            100.0,
            15.38,
            0.0,
            66.67,
            66.67,
            66.67,
            100.0,
            100.0,
            100.0,
            50.0,
            100.0,
            25.0,
            100.0,
            0.0,
            100.0,
            0.0,
            85.71,
            0.0,
            100.0,
            0.0,
            0.0,
            0.0,
            100.0,
            100.0,
            100.0,
            100.0,
            100.0,
            100.0,
            100.0,
            100.0,
            0.0,
            100.0,
            75.0,
            100.0,
            100.0,
            0.0,
            69.57,
            100.0,
            88.89,
            100.0,
            100.0,
            75.0,
            100.0,
            66.67,
            0.0,
            0.0,
            100.0,
            100.0,
            80.0,
            100.0,
            100.0,
            66.67,
            100.0,
            0.0,
            33.33,
            100.0,
            100.0,
            0.0,
            100.0,
            100.0,
            90.91,
            100.0,
            66.67,
            0.0,
            100.0,
            100.0,
            66.67,
            100.0,
            66.67,
            100.0,
            100.0,
            100.0,
            100.0,
            50.0,
            15.38,
            100.0,
            0.0,
            100.0,
            100.0,
            100.0,
            0.0,
            100.0
        ],
        "cost_list": [
            0.006917499999999999,
            0.008133499999999998,
            0.009187,
            0.008791999999999998,
            0.0076475,
            0.0076305,
            0.008057499999999999,
            0.0091845,
            0.0074,
            0.007623499999999999,
            0.007343,
            0.0080605,
            0.007247999999999999,
            0.0075994999999999995,
            0.0068785,
            0.0074445,
            0.008131999999999999,
            0.015495,
            0.006033999999999999,
            0.0083885,
            0.009257499999999998,
            0.0070845,
            0.00788,
            0.011071,
            0.0088675,
            0.0072499999999999995,
            0.006895000000000001,
            0.007393,
            0.0079455,
            0.0076535,
            0.007138,
            0.008104,
            0.007556,
            0.0063595,
            0.006703999999999999,
            0.0084795,
            0.007378499999999999,
            0.0080545,
            0.008043,
            0.006870499999999999,
            0.006718999999999999,
            0.0072585,
            0.009406499999999998,
            0.009341499999999999,
            0.006994,
            0.0065035,
            0.0074919999999999995,
            0.008374,
            0.0071115,
            0.007096,
            0.0077824999999999995,
            0.007196999999999999,
            0.006564,
            0.0081865,
            0.013542,
            0.007375499999999999,
            0.007764999999999999,
            0.0077695,
            0.0066615,
            0.0078039999999999984,
            0.0071275,
            0.006946000000000001,
            0.007276999999999999,
            0.007691,
            0.007817999999999999,
            0.00782,
            0.007404499999999999,
            0.009115,
            0.007698,
            0.007391999999999999,
            0.0081945,
            0.0066045,
            0.008503,
            0.0065495,
            0.007658,
            0.007382999999999999,
            0.0065840000000000004,
            0.0087755,
            0.007568,
            0.007924500000000001,
            0.006448,
            0.007500999999999999,
            0.008417,
            0.007063000000000001,
            0.007039,
            0.007013,
            0.0069965,
            0.006701499999999998,
            0.008008,
            0.0071224999999999995,
            0.010033499999999999,
            0.007096,
            0.00713,
            0.0067374999999999996,
            0.007583,
            0.0073215,
            0.008092,
            0.007774,
            0.007333999999999999,
            0.007859,
            0.008802,
            0.006664499999999999,
            0.0066890000000000005,
            0.008448999999999998,
            0.00796,
            0.0091815,
            0.008612499999999999,
            0.007152499999999999,
            0.008448,
            0.008232999999999999,
            0.0066415,
            0.0080285,
            0.008059499999999999,
            0.006537,
            0.0074305,
            0.00577,
            0.0078045,
            0.0069064999999999994,
            0.007954499999999998,
            0.007631499999999999,
            0.0077755,
            0.008421000000000001,
            0.008785,
            0.006819499999999999,
            0.007917500000000001,
            0.0085335,
            0.006794999999999999,
            0.006282499999999999
        ],
        "test_fitness": "95% Bootstrap Confidence Interval: (66.0%, 69.2%), Median: 75.7%",
        "test_acc_list": [
            100.0,
            0.0,
            100.0,
            100.0,
            26.67,
            66.67,
            100.0,
            0.0,
            66.67,
            100.0,
            100.0,
            100.0,
            100.0,
            100.0,
            100.0,
            100.0,
            100.0,
            100.0,
            100.0,
            0.0,
            100.0,
            100.0,
            100.0,
            100.0,
            100.0,
            90.91,
            47.06,
            100.0,
            0.0,
            100.0,
            100.0,
            100.0,
            100.0,
            100.0,
            100.0,
            100.0,
            55.56,
            0.0,
            100.0,
            0.0,
            100.0,
            100.0,
            0.0,
            100.0,
            100.0,
            100.0,
            100.0,
            66.67,
            100.0,
            54.55,
            100.0,
            100.0,
            100.0,
            100.0,
            0.0,
            66.67,
            100.0,
            20.0,
            100.0,
            100.0,
            100.0,
            100.0,
            100.0,
            100.0,
            0.0,
            20.0,
            100.0,
            100.0,
            100.0,
            100.0,
            0.0,
            100.0,
            100.0,
            0.0,
            100.0,
            57.14,
            0.0,
            76.92,
            100.0,
            0.0,
            0.0,
            93.33,
            66.67,
            100.0,
            100.0,
            0.0,
            100.0,
            0.0,
            0.0,
            100.0,
            100.0,
            100.0,
            36.36,
            100.0,
            100.0,
            100.0,
            100.0,
            66.67,
            100.0,
            100.0,
            100.0,
            100.0,
            80.0,
            0.0,
            100.0,
            0.0,
            100.0,
            100.0,
            66.67,
            100.0,
            100.0,
            100.0,
            100.0,
            100.0,
            88.89,
            100.0,
            100.0,
            66.67,
            100.0,
            100.0,
            25.0,
            0.0,
            100.0,
            0.0,
            100.0,
            100.0,
            100.0,
            15.38,
            100.0,
            50.0,
            100.0,
            100.0,
            100.0,
            66.67,
            100.0,
            100.0,
            20.0,
            100.0,
            100.0,
            100.0,
            100.0,
            60.0,
            100.0,
            100.0,
            0.0,
            100.0,
            0.0,
            0.0,
            66.67,
            100.0,
            100.0,
            100.0,
            100.0,
            100.0,
            0.0,
            100.0,
            100.0,
            100.0,
            100.0,
            100.0,
            0.0,
            100.0,
            40.0,
            66.67,
            0.0,
            0.0,
            66.67,
            0.0,
            100.0,
            100.0,
            40.0,
            100.0,
            33.33,
            0.0,
            100.0,
            100.0,
            100.0,
            100.0,
            66.67,
            66.67,
            66.67,
            100.0,
            100.0,
            100.0,
            100.0,
            100.0,
            100.0,
            100.0,
            100.0,
            100.0,
            100.0,
            100.0,
            100.0,
            0.0,
            0.0,
            100.0,
            25.0,
            100.0,
            66.67,
            100.0
        ],
        "test_cost_list": [
            0.00721,
            0.008265999999999999,
            0.007428499999999999,
            0.007075,
            0.007911,
            0.0077625,
            0.007087999999999999,
            0.007672000000000001,
            0.0069505,
            0.008097,
            0.008187499999999999,
            0.005857,
            0.007481,
            0.009748,
            0.007548,
            0.006689499999999999,
            0.007313,
            0.009581500000000001,
            0.006895499999999999,
            0.009027,
            0.007743500000000001,
            0.0080355,
            0.007354499999999999,
            0.009513,
            0.008147999999999999,
            0.007420500000000001,
            0.007748,
            0.007247999999999999,
            0.0082345,
            0.007048499999999999,
            0.006705000000000001,
            0.006558999999999999,
            0.006943499999999999,
            0.0073939999999999995,
            0.009136000000000002,
            0.007905999999999998,
            0.007075499999999999,
            0.0104,
            0.006935500000000001,
            0.007253499999999999,
            0.00646,
            0.0072445,
            0.008527,
            0.0070515000000000005,
            0.007418499999999999,
            0.0074785,
            0.008623000000000002,
            0.008001,
            0.006682499999999999,
            0.009430499999999998,
            0.007383499999999998,
            0.0082205,
            0.0063755,
            0.007548999999999999,
            0.009476499999999999,
            0.0065945,
            0.006235999999999999,
            0.007469,
            0.0068779999999999996,
            0.0068775,
            0.0081385,
            0.008165500000000001,
            0.0085895,
            0.008121000000000001,
            0.007649,
            0.008423,
            0.006477500000000001,
            0.008184,
            0.010353499999999998,
            0.006435500000000001,
            0.007703,
            0.0072605,
            0.007958,
            0.010312499999999999,
            0.006592999999999999,
            0.0068945,
            0.0083035,
            0.006809,
            0.007436999999999999,
            0.008212500000000001,
            0.0088355,
            0.0074885,
            0.007364500000000001,
            0.008445499999999998,
            0.009704,
            0.0083225,
            0.0073145,
            0.0078425,
            0.006845000000000001,
            0.007995999999999998,
            0.006779499999999999,
            0.0072065,
            0.007038499999999999,
            0.007448499999999999,
            0.0090205,
            0.006847999999999999,
            0.007374500000000001,
            0.0080605,
            0.0061525,
            0.0075045,
            0.009631500000000001,
            0.0081835,
            0.0070065,
            0.0079735,
            0.0065014999999999995,
            0.009412,
            0.008755,
            0.007359500000000001,
            0.006996999999999999,
            0.008471,
            0.006866000000000001,
            0.0074895000000000005,
            0.0068650000000000004,
            0.009064999999999998,
            0.0070425,
            0.009029999999999998,
            0.0069775,
            0.006997999999999999,
            0.0060085,
            0.007987999999999999,
            0.007506499999999999,
            0.007764,
            0.00848,
            0.007983,
            0.007493,
            0.0086465,
            0.0072525,
            0.008657,
            0.0073360000000000005,
            0.006767500000000001,
            0.0066914999999999995,
            0.0060479999999999996,
            0.0079835,
            0.00863,
            0.008396500000000001,
            0.0075239999999999994,
            0.0086195,
            0.007530500000000001,
            0.0076844999999999995,
            0.0078925,
            0.008407,
            0.0069394999999999995,
            0.007854999999999997,
            0.006598999999999999,
            0.00838,
            0.0075315,
            0.0078405,
            0.008353499999999998,
            0.0074155,
            0.0072425,
            0.007271499999999999,
            0.0072994999999999996,
            0.0082165,
            0.006967,
            0.007234999999999999,
            0.007958,
            0.006721499999999999,
            0.0068125,
            0.008942000000000002,
            0.006863500000000001,
            0.007877000000000002,
            0.0076705,
            0.0070755,
            0.007008,
            0.00854,
            0.007904,
            0.0096585,
            0.009974999999999998,
            0.0072425,
            0.007648,
            0.0059854999999999995,
            0.0069255,
            0.0075965,
            0.007935999999999999,
            0.009661,
            0.007208999999999999,
            0.0064595,
            0.0070935,
            0.0069445,
            0.0060465,
            0.0085085,
            0.008688499999999998,
            0.008722999999999998,
            0.006192,
            0.007058,
            0.0079225,
            0.008173,
            0.008598,
            0.006435499999999999,
            0.0062315,
            0.006408,
            0.006240000000000001,
            0.007556,
            0.008720499999999999,
            0.006678,
            0.0068775,
            0.007095499999999999,
            0.007499999999999999,
            0.008018500000000001,
            0.006179
        ]
    }
]