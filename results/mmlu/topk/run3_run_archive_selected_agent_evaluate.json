[
    {
        "thought": "To enhance its performance, an LLM can iteratively improve its answer based on feedback. By reflecting on its previous attempts and incorporating feedback, the model can refine its reasoning and provide a more accurate solution.",
        "name": "Self-Refine (Reflexion)",
        "code": "def forward(self, taskInfo):\n    # Instruction for initial reasoning\n    cot_initial_instruction = \"Please think step by step and then solve the task.\"\n\n    # Instruction for reflecting on previous attempts and feedback to improve\n    cot_reflect_instruction = \"Given previous attempts and feedback, carefully consider where you could go wrong in your latest attempt. Using insights from previous attempts, try to solve the task better.\"\n    cot_agent = LLMAgentBase(['thinking', 'answer'], 'Chain-of-Thought Agent')\n\n    # Instruction for providing feedback and correcting the answer\n    critic_instruction = \"Please review the answer above and criticize on where might be wrong. If you are absolutely sure it is correct, output 'True' in 'correct'.\"\n    critic_agent = LLMAgentBase(['feedback', 'correct'], 'Critic Agent')\n    \n    N_max = 5 # Maximum number of attempts\n\n    # Initial attempt\n    cot_inputs = [taskInfo]\n    thinking, answer = cot_agent(cot_inputs, cot_initial_instruction, 0)\n\n    for i in range(N_max):\n        # Get feedback and correct status from the critic\n        feedback, correct = critic_agent([taskInfo, thinking, answer], critic_instruction, i)\n        if correct.content == 'True':\n            break\n            \n        # Add feedback to the inputs for the next iteration\n        cot_inputs.extend([thinking, answer, feedback])\n\n        # Reflect on previous attempts and refine the answer\n        thinking, answer = cot_agent(cot_inputs, cot_reflect_instruction, i + 1)\n    return answer\n",
        "generation": "initial",
        "fitness": "95% Bootstrap Confidence Interval: (62.5%, 78.1%), Median: 70.3%",
        "acc_list": [
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            0,
            1,
            0,
            1,
            0,
            1,
            1,
            0,
            0,
            0,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            0,
            1,
            1,
            0,
            1,
            1,
            1,
            1,
            0,
            0,
            1,
            0,
            1,
            1,
            1,
            0,
            0,
            0,
            1,
            1,
            0,
            0,
            0,
            1,
            1,
            1,
            0,
            0,
            1,
            1,
            1,
            0,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            0,
            0,
            1,
            0,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            0,
            1,
            0,
            0,
            1,
            1,
            1,
            1,
            1,
            1,
            0,
            0,
            0,
            1,
            0,
            1,
            1,
            0,
            1,
            1,
            1,
            1,
            0,
            1,
            1,
            1,
            1,
            0,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            0,
            1,
            1,
            1,
            0,
            1,
            1,
            1,
            0,
            0,
            1,
            0
        ],
        "cost_list": [
            0.00063,
            0.0008485000000000001,
            0.0014449999999999999,
            0.000717,
            0.0006464999999999999,
            0.000368,
            0.0004075,
            0.000338,
            0.0047225,
            0.000402,
            0.000312,
            0.0007700000000000001,
            0.001408,
            0.0031739999999999997,
            0.00030199999999999997,
            0.0032445,
            0.00182,
            0.0007535,
            0.0004435,
            0.0007725,
            0.000384,
            0.0007374999999999999,
            0.000784,
            0.0006704999999999999,
            0.00033549999999999997,
            0.0029075000000000004,
            0.0014935,
            0.00030750000000000005,
            0.00031800000000000003,
            0.0031035000000000004,
            0.0003315,
            0.00066,
            0.0003025,
            0.0007909999999999999,
            0.0003535,
            0.0032224999999999997,
            0.000359,
            0.0004135,
            0.00030000000000000003,
            0.0008389999999999999,
            0.0025069999999999997,
            0.0002915,
            0.0003225,
            0.00133,
            0.0010034999999999998,
            0.00049,
            0.00034649999999999997,
            0.0004265,
            0.001099,
            0.0002675,
            0.000747,
            0.00035650000000000005,
            0.0007075,
            0.0023815,
            0.00046049999999999997,
            0.000287,
            0.0009325,
            0.000777,
            0.001199,
            0.000361,
            0.0007625,
            0.001415,
            0.000284,
            0.00041349999999999997,
            0.000381,
            0.000499,
            0.0007205,
            0.0037799999999999995,
            0.004077,
            0.00036950000000000004,
            0.002288,
            0.0004205,
            0.0008575,
            0.000362,
            0.000612,
            0.000746,
            0.00039150000000000003,
            0.0023580000000000003,
            0.0008810000000000001,
            0.001598,
            0.0008025,
            0.0035315,
            0.0005345,
            0.000301,
            0.0013089999999999998,
            0.000341,
            0.0009159999999999999,
            0.00075,
            0.0007545,
            0.0005355,
            0.0034874999999999997,
            0.002926,
            0.0003655,
            0.0006625,
            0.0011055000000000001,
            0.0029144999999999996,
            0.000285,
            0.0005815,
            0.0003855,
            0.000344,
            0.000401,
            0.0006920000000000001,
            0.0034585,
            0.000296,
            0.0010504999999999998,
            0.000271,
            0.00032,
            0.000719,
            0.001972,
            0.0002725,
            0.0006945,
            0.000349,
            0.0003215,
            0.0011049999999999999,
            0.001157,
            0.004126,
            0.0012175,
            0.000292,
            0.0009159999999999999,
            0.0031225000000000003,
            0.00045799999999999997,
            0.0002755,
            0.0008290000000000001,
            0.0007834999999999999,
            0.0012235,
            0.000791,
            0.000325,
            0.000388
        ],
        "test_fitness": "95% Bootstrap Confidence Interval: (54.5%, 68.0%), Median: 61.5%",
        "test_acc_list": [
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            0,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            0,
            1,
            1,
            0,
            1,
            0,
            1,
            1,
            0,
            1,
            0,
            0,
            0,
            1,
            1,
            0,
            0,
            0,
            0,
            0,
            0,
            1,
            1,
            1,
            0,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            0,
            1,
            0,
            0,
            1,
            0,
            1,
            1,
            0,
            0,
            0,
            1,
            1,
            1,
            1,
            1,
            0,
            0,
            1,
            0,
            1,
            0,
            0,
            1,
            1,
            0,
            1,
            1,
            0,
            0,
            1,
            1,
            0,
            0,
            0,
            0,
            0,
            1,
            0,
            1,
            1,
            0,
            0,
            0,
            0,
            1,
            1,
            1,
            0,
            0,
            1,
            1,
            1,
            0,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            0,
            0,
            1,
            0,
            1,
            1,
            0,
            1,
            1,
            0,
            1,
            0,
            1,
            0,
            1,
            1,
            0,
            1,
            1,
            0,
            1,
            1,
            0,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            0,
            0,
            1,
            1,
            1,
            0,
            1,
            1,
            1,
            1,
            0,
            1,
            1,
            0,
            1,
            1,
            0,
            0,
            1,
            0,
            1,
            0,
            1,
            1,
            0,
            1,
            1,
            0,
            0,
            1,
            0,
            0,
            1,
            0,
            1,
            1,
            1,
            1,
            0,
            0,
            1,
            1,
            0,
            0,
            0,
            1,
            1,
            0,
            0,
            1,
            0,
            1,
            0,
            1
        ],
        "test_cost_list": [
            0.001603,
            0.000446,
            0.0003595,
            0.0003025,
            0.0003885,
            0.0006225,
            0.0003165,
            0.000294,
            0.0003105,
            0.0009605,
            0.000741,
            0.0006899999999999999,
            0.0003645,
            0.000439,
            0.000312,
            0.0012925,
            0.000689,
            0.0015404999999999998,
            0.00035999999999999997,
            0.0026645,
            0.0020754999999999997,
            0.000315,
            0.0002895,
            0.00031499999999999996,
            0.0014185,
            0.0002905,
            0.00029949999999999996,
            0.0025080000000000002,
            0.001204,
            0.003289,
            0.0002605,
            0.002508,
            0.0005815,
            0.0003505,
            0.000312,
            0.0028074999999999997,
            0.0037324999999999997,
            0.00133,
            0.0014125,
            0.00041,
            0.0003625,
            0.0016090000000000002,
            0.00034199999999999996,
            0.0007554999999999999,
            0.0003405,
            0.00032799999999999995,
            0.0007825,
            0.0012790000000000002,
            0.000791,
            0.000662,
            0.0006845,
            0.00043599999999999997,
            0.001633,
            0.00045149999999999997,
            0.000455,
            0.002637,
            0.000318,
            0.000595,
            0.0008525,
            0.002496,
            0.0013325,
            0.00047749999999999995,
            0.0004305,
            0.0006284999999999999,
            0.000618,
            0.0005625000000000001,
            0.000696,
            0.0024419999999999997,
            0.0004915,
            0.0003285,
            0.0007030000000000001,
            0.00045449999999999993,
            0.001018,
            0.0008465,
            0.0029989999999999995,
            0.0003865,
            0.0007675,
            0.00042699999999999997,
            0.0017615,
            0.00043149999999999997,
            0.00028149999999999996,
            0.000437,
            0.0006505,
            0.0005855,
            0.0015119999999999999,
            0.00042699999999999997,
            0.000851,
            0.00029600000000000004,
            0.0011755,
            0.00028,
            0.000375,
            0.000319,
            0.00044050000000000003,
            0.003411,
            0.000463,
            0.0004785,
            0.0007725,
            0.001065,
            0.0005235,
            0.000616,
            0.0032649999999999997,
            0.0011365,
            0.000333,
            0.00028,
            0.0007815,
            0.000344,
            0.0003185,
            0.00042249999999999997,
            0.0003195,
            0.0006069999999999999,
            0.0003095,
            0.0003695,
            0.0033245,
            0.0032709999999999996,
            0.0004215,
            0.0007559999999999999,
            0.000769,
            0.0010309999999999998,
            0.0027120000000000004,
            0.0027114999999999995,
            0.0002985,
            0.000372,
            0.0004095,
            0.0026099999999999995,
            0.002823,
            0.00039549999999999996,
            0.000783,
            0.0003155,
            0.000331,
            0.0008684999999999999,
            0.000456,
            0.00031749999999999997,
            0.0014375,
            0.0025785,
            0.0002735,
            0.0029649999999999998,
            0.0003005,
            0.0006720000000000001,
            0.0003195,
            0.000307,
            0.0003245,
            0.000395,
            0.00036399999999999996,
            0.0013594999999999998,
            0.0003145,
            0.000405,
            0.0019510000000000005,
            0.003083,
            0.000438,
            0.00033949999999999996,
            0.000352,
            0.003149,
            0.0002825,
            0.0011995,
            0.0012404999999999998,
            0.0003315,
            0.0024384999999999997,
            0.00032550000000000005,
            0.000376,
            0.0008964999999999999,
            0.0033289999999999995,
            0.0019455000000000002,
            0.0008415,
            0.0012715,
            0.000741,
            0.0041505,
            0.0005794999999999999,
            0.0009660000000000001,
            0.002127,
            0.0007815,
            0.0024485,
            0.00027100000000000003,
            0.000267,
            0.001384,
            0.00045999999999999996,
            0.000422,
            0.0008405,
            0.0008155,
            0.0003495,
            0.0007210000000000001,
            0.00028,
            0.0007765000000000001,
            0.001286,
            0.001271,
            0.000483,
            0.000284,
            0.000724,
            0.0032990000000000003,
            0.0011765,
            0.0030659999999999997,
            0.0032699999999999995,
            0.0014695,
            0.0003145,
            0.002931,
            0.0018919999999999998,
            0.0003075,
            0.000807,
            0.000334,
            0.003694,
            0.00078
        ]
    },
    {
        "thought": "**Insights:**\nCombining insights from various expert agents in a structured way while incorporating an iterative refinement mechanism with domain-specific corrections can lead to more accurate solutions. Introducing a dedicated aggregation phase where multiple agents' insights are synthesized ensures a comprehensive understanding and robust final solution.\n\n**Overall Idea:**\nThe proposed architecture involves an initial reasoning phase by a generalist agent, followed by domain-specific corrective phases. Each domain-specific agent refines the solution iteratively. In the end, an aggregation agent consolidates all insights for the final answer.\n\n**Implementation:**\n1. Initial reasoning by a generalist agent to generate preliminary thoughts and a possible answer.\n2. Iterative domain-specific refinement phases: Each domain-specific agent provides corrections iteratively.\n3. Aggregation phase: Consolidate all corrected insights into a final answer.",
        "name": "Iterative Domain-Specific Refinement with Aggregation",
        "code": "def forward(self, taskInfo):\n    # Initial reasoning by the generalist agent\n    initial_instruction = 'Please think step by step and then solve the task based on your current knowledge.'\n    generalist_agent = LLMAgentBase(['thinking', 'answer'], 'Generalist Agent', temperature=0.7)\n    initial_outputs = generalist_agent([taskInfo], initial_instruction)\n    current_thinking, current_answer = initial_outputs[0], initial_outputs[1]\n\n    # Domain-specific refinement phases\n    domain_agents = [\n        LLMAgentBase(['feedback', 'correction'], 'Physics Agent', role='Physics Expert'),\n        LLMAgentBase(['feedback', 'correction'], 'Chemistry Agent', role='Chemistry Expert'),\n        LLMAgentBase(['feedback', 'correction'], 'Biology Agent', role='Biology Expert')\n    ]\n    max_iterations = 3\n    refined_thinking, refined_answer = current_thinking, current_answer\n\n    for i in range(max_iterations):\n        for agent in domain_agents:\n            refinement_instruction = 'Given the task, initial reasoning, and the current answer, provide feedback and corrections.'\n            outputs = agent([taskInfo, refined_thinking, refined_answer], refinement_instruction)\n            feedback, correction = outputs\n            # Accumulate feedback and corrections iteratively\n            refined_thinking = Info('thinking', 'Refinement Agent', refined_thinking.content + '\\n' + feedback.content, i)\n            refined_answer = correction\n\n    # Aggregation phase\n    aggregation_agent = LLMAgentBase(['thinking', 'answer'], 'Aggregation Agent', temperature=0.1)\n    aggregation_instruction = 'Given the task, initial reasoning, and all feedback from the domain-specific agents, consolidate all insights and provide the final answer.'\n    aggregated_outputs = aggregation_agent([taskInfo, refined_thinking, refined_answer], aggregation_instruction)\n    final_thinking, final_answer = aggregated_outputs\n\n    return final_answer\n",
        "fitness": "95% Bootstrap Confidence Interval: (65.6%, 80.5%), Median: 73.4%",
        "generation": 14,
        "acc_list": [
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            0,
            1,
            1,
            0,
            0,
            0,
            1,
            1,
            0,
            0,
            0,
            1,
            1,
            1,
            0,
            0,
            1,
            0,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            0,
            0,
            0,
            0,
            1,
            1,
            1,
            1,
            1,
            0,
            1,
            1,
            1,
            0,
            0,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            0,
            0,
            1,
            0,
            1,
            1,
            1,
            1,
            0,
            1,
            1,
            0,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            0,
            1,
            0,
            1,
            1,
            1,
            1,
            1,
            0,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            0,
            1,
            1,
            1,
            1,
            1,
            0,
            1,
            1,
            0,
            1,
            1,
            0,
            0,
            1,
            0,
            1,
            0,
            0,
            1,
            0
        ],
        "cost_list": [
            0.0023815,
            0.0031999999999999997,
            0.00434,
            0.0020879999999999996,
            0.0023710000000000003,
            0.0056145,
            0.0037905,
            0.0036695,
            0.0046,
            0.0028649999999999995,
            0.002321,
            0.0031699999999999996,
            0.005346,
            0.0044305,
            0.002273,
            0.0035414999999999995,
            0.0053045,
            0.0031349999999999998,
            0.003447499999999999,
            0.0032134999999999993,
            0.002915,
            0.0025250000000000003,
            0.0027314999999999996,
            0.0040230000000000005,
            0.0026325000000000003,
            0.0039115,
            0.003713,
            0.002054,
            0.0021005000000000004,
            0.0037065000000000006,
            0.0023005,
            0.0023490000000000004,
            0.0020210000000000002,
            0.002581,
            0.003665,
            0.0038005,
            0.0023725,
            0.00375,
            0.0023190000000000003,
            0.002823,
            0.002688,
            0.0029659999999999995,
            0.0027069999999999998,
            0.005264999999999999,
            0.0026715000000000003,
            0.00311,
            0.003306,
            0.0045545,
            0.0033145,
            0.001944,
            0.0036604999999999997,
            0.0034189999999999997,
            0.0024805,
            0.005481,
            0.0032655000000000006,
            0.0019069999999999996,
            0.0021464999999999995,
            0.0027949999999999997,
            0.004843,
            0.004037,
            0.0025725,
            0.0030294999999999996,
            0.0021425,
            0.002995,
            0.0038285000000000003,
            0.0047085,
            0.0035685,
            0.005946000000000001,
            0.004374999999999999,
            0.002851,
            0.003228,
            0.002995,
            0.0030029999999999996,
            0.0035565000000000006,
            0.004942,
            0.0029640000000000005,
            0.0030285000000000004,
            0.0032534999999999994,
            0.0035375,
            0.0065165,
            0.0035119999999999995,
            0.002732,
            0.0040314999999999995,
            0.002455,
            0.0032669999999999995,
            0.002281,
            0.0018765000000000001,
            0.003025,
            0.0032879999999999997,
            0.004968500000000001,
            0.003615,
            0.0034165,
            0.003605,
            0.0024225,
            0.004365000000000001,
            0.003098,
            0.001982,
            0.0024684999999999998,
            0.0028225,
            0.0033464999999999996,
            0.003119,
            0.003958,
            0.004104,
            0.0021929999999999996,
            0.0019635,
            0.0019320000000000001,
            0.0022034999999999997,
            0.005750000000000001,
            0.004991499999999999,
            0.002226,
            0.002116,
            0.002483,
            0.002556,
            0.002245,
            0.0041265,
            0.006406000000000001,
            0.0034435,
            0.0023404999999999997,
            0.0034089999999999997,
            0.0036850000000000003,
            0.0044915,
            0.0023214999999999998,
            0.003504,
            0.0022294999999999997,
            0.004573,
            0.0029835,
            0.0024995,
            0.003634
        ],
        "test_fitness": "95% Bootstrap Confidence Interval: (55.0%, 68.5%), Median: 62.0%",
        "test_acc_list": [
            1,
            1,
            0,
            1,
            1,
            1,
            1,
            1,
            1,
            0,
            0,
            1,
            0,
            1,
            1,
            1,
            1,
            0,
            1,
            0,
            0,
            1,
            1,
            1,
            0,
            1,
            1,
            0,
            1,
            0,
            1,
            1,
            1,
            1,
            0,
            0,
            0,
            0,
            1,
            1,
            1,
            0,
            1,
            0,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            0,
            1,
            1,
            0,
            1,
            1,
            0,
            0,
            1,
            1,
            1,
            1,
            0,
            1,
            0,
            0,
            0,
            0,
            1,
            0,
            0,
            1,
            0,
            0,
            1,
            0,
            0,
            0,
            0,
            1,
            1,
            0,
            1,
            0,
            0,
            1,
            0,
            1,
            1,
            1,
            0,
            0,
            1,
            1,
            0,
            1,
            0,
            1,
            1,
            1,
            0,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            0,
            0,
            1,
            0,
            1,
            1,
            0,
            1,
            1,
            0,
            0,
            0,
            1,
            0,
            1,
            1,
            0,
            1,
            1,
            0,
            1,
            1,
            0,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            0,
            1,
            1,
            1,
            1,
            1,
            0,
            1,
            1,
            0,
            0,
            1,
            0,
            1,
            0,
            0,
            1,
            0,
            1,
            1,
            0,
            0,
            1,
            0,
            0,
            1,
            0,
            1,
            1,
            0,
            0,
            0,
            0,
            1,
            1,
            0,
            1,
            0,
            1,
            0,
            0,
            1,
            1,
            0,
            1,
            0,
            1
        ],
        "test_cost_list": [
            0.0038064999999999996,
            0.0029819999999999994,
            0.002713,
            0.0021439999999999996,
            0.0023774999999999994,
            0.001977,
            0.0023425,
            0.0022335000000000002,
            0.0022259999999999997,
            0.003282,
            0.002799,
            0.0025854999999999997,
            0.0034454999999999998,
            0.0031745,
            0.0032655,
            0.0040479999999999995,
            0.002304,
            0.003408,
            0.003649,
            0.004545,
            0.005484,
            0.0020735,
            0.0035685,
            0.0019465,
            0.0033725,
            0.0018985,
            0.002035,
            0.0032784999999999997,
            0.0029639999999999996,
            0.0049775,
            0.0029630000000000004,
            0.0023950000000000004,
            0.004232,
            0.004025,
            0.0029279999999999996,
            0.0029995000000000004,
            0.004965499999999999,
            0.0038369999999999997,
            0.0052715,
            0.004152,
            0.0029289999999999997,
            0.0036979999999999995,
            0.0028004999999999996,
            0.004762499999999999,
            0.0025380000000000003,
            0.0032580000000000005,
            0.003518,
            0.0037700000000000003,
            0.003691,
            0.0021674999999999997,
            0.002733,
            0.004006999999999999,
            0.00277,
            0.0035175,
            0.0025869999999999995,
            0.0036780000000000003,
            0.0025015000000000003,
            0.00351,
            0.0034800000000000005,
            0.003771,
            0.003929,
            0.0037485000000000005,
            0.004444,
            0.0048185,
            0.005553499999999999,
            0.0024135,
            0.0030780000000000004,
            0.0026404999999999996,
            0.0036299999999999995,
            0.0024664999999999995,
            0.0026060000000000002,
            0.0035565,
            0.004005999999999999,
            0.003772,
            0.004613,
            0.002942,
            0.0027829999999999994,
            0.003188,
            0.004605,
            0.0034339999999999996,
            0.00291,
            0.002654,
            0.0032344999999999995,
            0.0052825,
            0.003808,
            0.003535,
            0.0037,
            0.0033805,
            0.004684,
            0.0021014999999999996,
            0.004408,
            0.002103,
            0.0037325,
            0.0043815,
            0.0032964999999999995,
            0.004251,
            0.0036875,
            0.0028160000000000004,
            0.004165499999999999,
            0.0022815,
            0.004055,
            0.002757,
            0.0029534999999999995,
            0.0023174999999999997,
            0.002315,
            0.0033745,
            0.002112,
            0.0032470000000000003,
            0.002365,
            0.0023845000000000003,
            0.002806,
            0.0031485000000000003,
            0.0037875,
            0.003906499999999999,
            0.003764,
            0.0026174999999999996,
            0.0038929999999999998,
            0.0024740000000000005,
            0.0035135,
            0.0033109999999999993,
            0.0024604999999999996,
            0.0030115000000000003,
            0.003744,
            0.005728,
            0.0025544999999999995,
            0.00294,
            0.00326,
            0.0022505000000000003,
            0.002443,
            0.003575,
            0.003928999999999999,
            0.00244,
            0.0048295000000000005,
            0.0025,
            0.0022595000000000002,
            0.0047355,
            0.0020575,
            0.003029,
            0.002376,
            0.0018114999999999995,
            0.0028055000000000003,
            0.0044625,
            0.002711,
            0.004638499999999999,
            0.0024935000000000005,
            0.0026349999999999998,
            0.0039715,
            0.0028199999999999996,
            0.0033074999999999997,
            0.002374,
            0.0036044999999999996,
            0.0035819999999999997,
            0.0021219999999999998,
            0.00418,
            0.003297,
            0.0027354999999999997,
            0.003985,
            0.0019015,
            0.0040195000000000005,
            0.003095,
            0.0028415,
            0.005070500000000001,
            0.0035765000000000003,
            0.0044615,
            0.002985,
            0.0050255000000000005,
            0.0020255,
            0.0041035,
            0.003466,
            0.006101499999999999,
            0.0039605,
            0.0019744999999999997,
            0.0023599999999999997,
            0.0035849999999999996,
            0.004412,
            0.0035325,
            0.0037549999999999997,
            0.0060290000000000005,
            0.0023985000000000005,
            0.0033859999999999997,
            0.0017980000000000001,
            0.0025164999999999996,
            0.0034104999999999995,
            0.0032975,
            0.004371,
            0.0031484999999999994,
            0.0024110000000000004,
            0.0033394999999999996,
            0.0029655,
            0.0043064999999999996,
            0.0042380000000000004,
            0.0044185,
            0.003965499999999999,
            0.0044494999999999995,
            0.0041335,
            0.004229,
            0.006955999999999999,
            0.0025395000000000005,
            0.0030060000000000004,
            0.002448
        ]
    }
]